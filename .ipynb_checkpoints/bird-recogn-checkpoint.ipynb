{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "be59eb13",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 00:07:04.904843: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743206825.085812    3828 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743206825.140079    3828 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-29 00:07:05.556147: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "111fb351",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando e pré-processando imagens...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configurações\n",
    "DATA_DIR = \"/home/joao/Documents/GitHub/Bird-Recognition/dataset\"  # Substitua pelo caminho do seu dataset\n",
    "OUTPUT_DIR = 'preprocessed_data'  # Pasta para salvar os arquivos pickle\n",
    "IMG_SIZE = (224, 224)  # Tamanho padrão para muitas arquiteturas CNN\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Lista de espécies (conforme a proposta)\n",
    "species = [\n",
    "    'Ciconia_ciconia', 'Columba_livia', 'Streptopelia_decaocto',\n",
    "    'Emberiza_calandra', 'Carduelis_carduelis', 'Serinus_serinus',\n",
    "    'Delichon_urbicum', 'Hirundo_rustica', 'Passer_domesticus',\n",
    "    'Sturnus_unicolor', 'Turdus_merula'\n",
    "]\n",
    "\n",
    "# Criar pasta de saída se não existir\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Função para carregar e pré-processar imagens\n",
    "def load_and_preprocess_images(data_dir, species_list, img_size):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, specie in enumerate(species_list):\n",
    "        specie_dir = data_dir+\"/\"+specie\n",
    "        \n",
    "        for img_name in os.listdir(specie_dir):\n",
    "            img_path = os.path.join(specie_dir, img_name)\n",
    "            \n",
    "            try:\n",
    "                # Carregar imagem\n",
    "                img = Image.open(img_path)\n",
    "                \n",
    "                # Converter para RGB (caso tenha canais alpha)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Redimensionar\n",
    "                img = img.resize(img_size)\n",
    "                \n",
    "                # Converter para array e normalizar [0, 1]\n",
    "                img_array = np.array(img) / 255.0\n",
    "                \n",
    "                images.append(img_array)\n",
    "                labels.append(idx)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Carregar e pré-processar imagens\n",
    "print(\"Carregando e pré-processando imagens...\")\n",
    "X, y = load_and_preprocess_images(DATA_DIR, species, IMG_SIZE)\n",
    "\n",
    "# Dividir em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, stratify=y\n",
    ")\n",
    "\n",
    "# Aplicar aumento de dados apenas no conjunto de treino\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Configurar gerador de treino com aumento de dados\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train, y_train,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Configurar gerador de teste sem aumento de dados\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(\n",
    "    X_test, y_test,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Salvar os dados em arquivos pickle\n",
    "print(\"Salvando dados pré-processados...\")\n",
    "\n",
    "# Salvar conjuntos originais (sem aumento)\n",
    "with open(os.path.join(OUTPUT_DIR, 'train_data.pkl'), 'wb') as f:\n",
    "    pickle.dump({'X': X_train, 'y': y_train}, f)\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'test_data.pkl'), 'wb') as f:\n",
    "    pickle.dump({'X': X_test, 'y': y_test}, f)\n",
    "\n",
    "# Salvar geradores (opcional - normalmente não é necessário salvar os geradores)\n",
    "# Mas vamos salvar as informações necessárias para recriá-los\n",
    "generator_info = {\n",
    "    'train_datagen_params': train_datagen.get_config(),\n",
    "    'test_datagen_params': test_datagen.get_config(),\n",
    "    'batch_size': BATCH_SIZE\n",
    "}\n",
    "\n",
    "with open(os.path.join(OUTPUT_DIR, 'generator_info.pkl'), 'wb') as f:\n",
    "    pickle.dump(generator_info, f)\n",
    "\n",
    "# Salvar lista de espécies\n",
    "with open(os.path.join(OUTPUT_DIR, 'species.pkl'), 'wb') as f:\n",
    "    pickle.dump(species, f)\n",
    "\n",
    "print(\"Pré-processamento concluído e dados salvos em:\")\n",
    "print(f\"- {os.path.join(OUTPUT_DIR, 'train_data.pkl')}\")\n",
    "print(f\"- {os.path.join(OUTPUT_DIR, 'test_data.pkl')}\")\n",
    "print(f\"- {os.path.join(OUTPUT_DIR, 'generator_info.pkl')}\")\n",
    "print(f\"- {os.path.join(OUTPUT_DIR, 'species.pkl')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
