{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "960e8fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import json\n",
    "import csv\n",
    "import cv2\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, top_k_accuracy_score, precision_recall_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e91bd82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = [\n",
    "    'Ciconia_ciconia', 'Columba_livia', 'Streptopelia_decaocto',\n",
    "    'Emberiza_calandra', 'Carduelis_carduelis', 'Serinus_serinus',\n",
    "    'Delichon_urbicum', 'Hirundo_rustica', 'Passer_domesticus',\n",
    "    'Sturnus_unicolor', 'Turdus_merula'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f34b76ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Experiment B parameters\\nMIXUP_ALPHA = 0.2\\nCUTMIX_ALPHA = 1.0\\nUSE_MIXUP = True\\nUSE_CUTMIX = True\\n\\n# Experiment E parameters\\nUNCERTAINTY_THRESHOLD = 0.6'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_SAVE_DIR = 'saved_models/full_image_model'\n",
    "RESULT_DIR = 'images'  \n",
    "DATA_DIR = \"full_image_dataset\"\n",
    "AUGMENTED_DATA_DIR = \"augmented_dataset\"\n",
    "DATASET = 'dataset_20250523_165448.h5'\n",
    "BATCH_SIZE = [32]\n",
    "N_SPLITS = 5                            \n",
    "NUM_EPOCHS = 25\n",
    "NUM_CLASSES = len(species)\n",
    "\n",
    "\"\"\"# Experiment B parameters\n",
    "MIXUP_ALPHA = 0.2\n",
    "CUTMIX_ALPHA = 1.0\n",
    "USE_MIXUP = True\n",
    "USE_CUTMIX = True\n",
    "\n",
    "# Experiment E parameters\n",
    "UNCERTAINTY_THRESHOLD = 0.6\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3144104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openH5File(filepath, fold_idx, include_test=False):\n",
    "    file = h5py.File(filepath, 'r')\n",
    "    datasets = {}\n",
    "\n",
    "    if fold_idx is not None:\n",
    "        try:\n",
    "            fold_group = file[f'cross_validation/fold_{fold_idx}']\n",
    "            datasets['X_train'] = fold_group['X_train'][:]  # Load into memory\n",
    "            datasets['y_train'] = fold_group['y_train'][:]\n",
    "            datasets['X_val'] = fold_group['X_val'][:]\n",
    "            datasets['y_val'] = fold_group['y_val'][:]\n",
    "        except KeyError:\n",
    "            file.close()\n",
    "            raise ValueError(f\"Fold {fold_idx} not found\")\n",
    "    else:\n",
    "        datasets['X_train'] = file['train']['X_train'][:]\n",
    "        datasets['y_train'] = file['train']['y_train'][:]\n",
    "        datasets['X_val'] = file['val']['X_val'][:]\n",
    "        datasets['y_val'] = file['val']['y_val'][:]\n",
    "\n",
    "    if include_test:\n",
    "        datasets['X_test'] = file['test']['X_test'][:]\n",
    "        datasets['y_test'] = file['test']['y_test'][:]\n",
    "\n",
    "    file.close()\n",
    "    return datasets\n",
    "\n",
    "def createDataloaders(X, y, batch_size, shuffle=False):\n",
    "    if X.ndim == 4 and X.shape[-1] in {1, 3}:  # NHWC → NCHW\n",
    "        X = np.transpose(X, (0, 3, 1, 2))\n",
    "\n",
    "    X_tensor = torch.from_numpy(X).float()\n",
    "    y_tensor = torch.from_numpy(y).long()\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    return DataLoader(dataset, batch_size, shuffle, num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "def getDataloaders(filepath, fold_idx, batch_size, include_test=False):\n",
    "    dataset = openH5File(filepath, fold_idx, include_test)\n",
    "    train_loader, val_loader, test_loader = None, None, None\n",
    "\n",
    "    if fold_idx is not None:\n",
    "        # Cross-validation mode (train/val only)\n",
    "        train_loader = createDataloaders(dataset['X_train'], dataset['y_train'], batch_size, shuffle=True)\n",
    "        val_loader = createDataloaders(dataset['X_val'], dataset['y_val'], batch_size)\n",
    "    else:\n",
    "        # Full dataset mode (train/val/test)\n",
    "        train_loader = createDataloaders(dataset['X_train'], dataset['y_train'], batch_size, shuffle=True)\n",
    "        val_loader = createDataloaders(dataset['X_val'], dataset['y_val'], batch_size)\n",
    "        if include_test:\n",
    "            test_loader = createDataloaders(dataset['X_test'], dataset['y_test'], batch_size)\n",
    "    return train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96c91983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def frezee_layers(model):\\n    for param in model.features.parameters():\\n        param.requires_grad = False\\n\\ndef unfreeze_layers(model, unfreeze_from_layer=3):\\n    for i, block in enumerate(model.features):\\n        if i >= unfreeze_from_layer:\\n            for param in block.parameters():\\n                param.requires_grad = True\\n\\ndef apply_mixup_cutmix(inputs, labels, params):\\n    if not (USE_MIXUP or USE_CUTMIX):\\n        return inputs, (labels, labels, 1.0)\\n\\n    use_mixup = params.get('use_mixup', False)\\n    use_cutmix = params.get('use_cutmix', False)\\n\\n    if use_cutmix:\\n        lam = np.random.beta(CUTMIX_ALPHA, CUTMIX_ALPHA)\\n        b, _, h, w = inputs.size()\\n\\n        # Generate random bounding box\\n        rx = random.randint(0, w)\\n        ry = random.randint(0, h)\\n        rw = int(w * np.sqrt(1 - lam))\\n        rh = int(h * np.sqrt(1 - lam))\\n        x1 = max(0, rx - rw // 2)\\n        y1 = max(0, ry - rh // 2)\\n        x2 = min(w, x1 + rw)\\n        y2 = min(h, y1 + rh)\\n\\n        # Apply CutMix\\n        inputs[:, :, y1:y2, x1:x2] = inputs.flip(0)[:, :, y1:y2, x1:x2]\\n        lam = 1 - (x2 - x1) * (y2 - y1) / (w * h)\\n    else:\\n        # Apply MixUp\\n        lam = np.random.beta(MIXUP_ALPHA, MIXUP_ALPHA)\\n        inputs = lam * inputs + (1 - lam) * inputs.flip(0)\\n\\n    # Return mixed labels and lambda\\n    return inputs, (labels, labels.flip(0), lam)\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getModel(name, nClasses, dropout_rate=0):\n",
    "    if name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "        target_layer = \"features.8\"\n",
    "    elif name == 'efficientnet_V2':\n",
    "        model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "        target_layer = \"features.7\"\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return model.to(DEVICE), target_layer\n",
    "\n",
    "def getOptimizer(model, params):\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'adamw':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    return optimizer\n",
    "\n",
    "#### MILESTONE 2 NEW FUNCTIONS ####\n",
    "\"\"\"def frezee_layers(model):\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_layers(model, unfreeze_from_layer=3):\n",
    "    for i, block in enumerate(model.features):\n",
    "        if i >= unfreeze_from_layer:\n",
    "            for param in block.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "def apply_mixup_cutmix(inputs, labels, params):\n",
    "    if not (USE_MIXUP or USE_CUTMIX):\n",
    "        return inputs, (labels, labels, 1.0)\n",
    "    \n",
    "    use_mixup = params.get('use_mixup', False)\n",
    "    use_cutmix = params.get('use_cutmix', False)\n",
    "    \n",
    "    if use_cutmix:\n",
    "        lam = np.random.beta(CUTMIX_ALPHA, CUTMIX_ALPHA)\n",
    "        b, _, h, w = inputs.size()\n",
    "        \n",
    "        # Generate random bounding box\n",
    "        rx = random.randint(0, w)\n",
    "        ry = random.randint(0, h)\n",
    "        rw = int(w * np.sqrt(1 - lam))\n",
    "        rh = int(h * np.sqrt(1 - lam))\n",
    "        x1 = max(0, rx - rw // 2)\n",
    "        y1 = max(0, ry - rh // 2)\n",
    "        x2 = min(w, x1 + rw)\n",
    "        y2 = min(h, y1 + rh)\n",
    "        \n",
    "        # Apply CutMix\n",
    "        inputs[:, :, y1:y2, x1:x2] = inputs.flip(0)[:, :, y1:y2, x1:x2]\n",
    "        lam = 1 - (x2 - x1) * (y2 - y1) / (w * h)\n",
    "    else:\n",
    "        # Apply MixUp\n",
    "        lam = np.random.beta(MIXUP_ALPHA, MIXUP_ALPHA)\n",
    "        inputs = lam * inputs + (1 - lam) * inputs.flip(0)\n",
    "    \n",
    "    # Return mixed labels and lambda\n",
    "    return inputs, (labels, labels.flip(0), lam)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd819fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, train_loader, val_loader, params):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getOptimizer(model, params)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3) if params['scheduler'] else None\n",
    "    \n",
    "    best_f1 = 0\n",
    "    THRESHOLD = 5\n",
    "    improvementCounter = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            improvementCounter = 0\n",
    "        else:\n",
    "            improvementCounter +=1\n",
    "            if improvementCounter >= THRESHOLD:\n",
    "                break\n",
    "\n",
    "    return history, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cf0f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocessImage(img_path):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = transforms.ToTensor()(img)\n",
    "    img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img)\n",
    "    img = img.unsqueeze(0) \n",
    "    return img\n",
    "\n",
    "def getClassLabel(preds):\n",
    "    _, class_idx = torch.max(preds, 1)\n",
    "    return class_idx.item()\n",
    "\n",
    "def getConvLayer(model, conv_layer_name):\n",
    "    for name, layer in model.named_modules():\n",
    "        if name == conv_layer_name:\n",
    "            return layer\n",
    "    raise ValueError(f\"Layer {conv_layer_name} not found in model.\")\n",
    "\n",
    "def overlay_heatmap(img_path, heatmap, alpha=0.4):\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    superimposed_img = cv2.addWeighted(img, alpha, heatmap, 1-alpha, 0)\n",
    "    return superimposed_img\n",
    "\n",
    "def computeGradCam(model, img_tensor, class_idx, conv_layer_name):\n",
    "    conv_layer_name = getConvLayer(model, conv_layer_name)\n",
    "\n",
    "    activations = None\n",
    "    def forward_hook(module, input, output):\n",
    "        nonlocal activations\n",
    "        activations = output\n",
    "    \n",
    "    hook = conv_layer_name.register_forward_hook(forward_hook)\n",
    "\n",
    "    img_tensor.requires_grad_(True)\n",
    "    preds = model(img_tensor)\n",
    "    loss = preds[:, class_idx]\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    grads = img_tensor.grad.cpu().numpy()\n",
    "    pooled_grads = np.mean(grads, axis=(0, 2, 3))\n",
    "\n",
    "    hook.remove()\n",
    "\n",
    "    activations = activations.detach().cpu().numpy()[0]\n",
    "    for i in range(len(pooled_grads)):\n",
    "        activations[i, :] *= pooled_grads[i]\n",
    "    heatmap = np.mean(activations, axis=0)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "def genGRADCAM(model, target_layer, test_loader, species_list):\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    cam_results = []\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            class_idx = labels[i].item()\n",
    "            img_tensor = inputs[i].unsqueeze(0)\n",
    "\n",
    "            # Save temporary image for OpenCV overlay\n",
    "            img_np = img_tensor.squeeze().cpu().numpy()\n",
    "            img_np = np.transpose(img_np, (1, 2, 0))  # C,H,W → H,W,C\n",
    "            img_np = (img_np * 255).astype(np.uint8)\n",
    "            temp_path = 'temp_image.jpg'\n",
    "            cv2.imwrite(temp_path, img_np[..., ::-1])  # RGB to BGR\n",
    "\n",
    "            heatmap = computeGradCam(model, img_tensor, class_idx, target_layer)\n",
    "            output_img = overlay_heatmap(temp_path, heatmap)\n",
    "\n",
    "            cam_results.append({\n",
    "                'class_name': species_list[class_idx],\n",
    "                'image': output_img[..., ::-1],  # BGR to RGB\n",
    "                'original': img_np\n",
    "            })\n",
    "\n",
    "            # Just one per class (optional early stop)\n",
    "            if len(cam_results) >= len(species_list):\n",
    "                return cam_results\n",
    "\n",
    "    return cam_results\n",
    "\n",
    "\n",
    "\n",
    "def saveGRADCAM(gradcam_results, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for result in gradcam_results:\n",
    "        filename = f\"gradcam_{result['class_name']}.png\"\n",
    "        image = result['image']\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray((image * 255).astype(np.uint8)) if image.max() <= 1.0 else Image.fromarray(image)\n",
    "        image.save(os.path.join(save_dir, filename))\n",
    "\n",
    "\n",
    "def plotGRADCAM(gradcam_results, save_path):\n",
    "    cols = NUM_CLASSES\n",
    "    rows = 2 \n",
    "\n",
    "    plt.figure(figsize=(5 * cols, 5 * rows))\n",
    "    \n",
    "    for i, result in enumerate(gradcam_results):\n",
    "        # Original image (first row)\n",
    "        plt.subplot(rows, cols, i + 1) \n",
    "        plt.imshow(result['original'])\n",
    "        plt.title(f\"{result['class_name']}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Grad-CAM image (second row)\n",
    "        plt.subplot(rows, cols, cols + i + 1)\n",
    "        plt.imshow(result['image'])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plotting(history, cm, metrics_dict, species, cam_images=None):\n",
    "    # Plot training and evaluation graphs\n",
    "    grad_path = os.path.join(MODEL_SAVE_DIR, RESULT_DIR, f\"gradcams_{datetime.now().strftime('%Y%m%d')}.png\")\n",
    "    fig1 = plt.figure(figsize=(24, 8))\n",
    "\n",
    "    # Training history\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Confusion matrix\n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=species, yticklabels=species)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Precision-recall\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(metrics_dict['recall'], metrics_dict['precision'], lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall (AUPRC: {metrics_dict[\"macro_auprc\"]:.4f})')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path_graphs = os.path.join(MODEL_SAVE_DIR, RESULT_DIR, f\"training_graphs_{datetime.now().strftime('%Y%m%d')}.png\")\n",
    "    plt.savefig(plot_path_graphs, dpi=300)\n",
    "    plt.close(fig1)\n",
    "\n",
    "    # Plot Grad-CAMs\n",
    "    if cam_images:\n",
    "        plotGRADCAM(cam_images, grad_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b07856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(filepath, n_splits, hyperparams):\n",
    "    results_log = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        \"total_combinations\": len(list(itertools.product(*hyperparams.values()))),\n",
    "        \"best_f1\": 0,\n",
    "        \"best_params\": None,\n",
    "        \"all_results\": []\n",
    "    }\n",
    "\n",
    "    # Generate all possible hyperparameter combinations\n",
    "    param_combinations = [dict(zip(hyperparams.keys(), v)) \n",
    "                         for v in itertools.product(*hyperparams.values())]\n",
    "    print(f\"\\nBeginning GridSearch with {len(param_combinations)} combinations...\")\n",
    "    \n",
    "    for params in tqdm(param_combinations):\n",
    "        #torch.cuda.reset_peak_memory_stats()\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Testing combination: {params}\")\n",
    "        fold_f1_scores = []\n",
    "        fold_acc_scores = []\n",
    "        start_time = time.time()\n",
    "        memory_tracker = []\n",
    "        \n",
    "        # Cross-validation loop\n",
    "        for fold_idx in range(1, n_splits+1):\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            train_loader, val_loader, _ = getDataloaders(filepath, fold_idx, params['batch_size'], False)\n",
    "            model, _ = getModel(params['model_name'], NUM_CLASSES, params.get('dropout_rate', 0))\n",
    "            history, fold_f1 = trainModel(model, train_loader, val_loader, params)\n",
    "            print(f\"Fold {fold_idx} Best F1 Score: {fold_f1:.4f}\")\n",
    "            fold_f1_scores.append(fold_f1)\n",
    "            fold_acc_scores.append(history['val_acc'][-1].item())\n",
    "            memory_tracker.append(torch.cuda.max_memory_allocated()/1e9)\n",
    "\n",
    "            # Clean up\n",
    "            del model, train_loader, val_loader\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Calculate average F1 across folds\n",
    "        avg_f1 = np.mean(fold_f1_scores)\n",
    "        std_f1 = np.std(fold_f1_scores)\n",
    "        avg_acc = np.mean(fold_acc_scores)\n",
    "        std_acc = np.std(fold_acc_scores)\n",
    "        time_taken = time.time() - start_time\n",
    "        avg_memory = np.mean(memory_tracker)\n",
    "\n",
    "        # Record this combination's results\n",
    "        result_entry = {\n",
    "            \"params\": params,\n",
    "            \"avg_f1\": avg_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_acc\": avg_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"f1_scores\": fold_f1_scores,\n",
    "            \"acc_scores\": fold_acc_scores,\n",
    "            \"memory_used_GB\": avg_memory,\n",
    "            \"time_taken\": time_taken\n",
    "        }\n",
    "        results_log[\"all_results\"].append(result_entry)\n",
    "        \n",
    "        # Update best parameters if improved\n",
    "        if avg_f1 > results_log[\"best_f1\"]:\n",
    "            results_log[\"best_f1\"] = avg_f1\n",
    "            results_log[\"best_params\"] = params\n",
    "            print(f\"New best parameters found with F1: {avg_f1:.4f}\")\n",
    "\n",
    "    # Finalize results        \n",
    "    print(\"\\nGridSearch completed!\")\n",
    "    torch.save(results_log[\"best_params\"], os.path.join(MODEL_SAVE_DIR, f'gridsearch_setup1_{datetime.now().strftime(\"%Y%m%d\")}.pth'))\n",
    "\n",
    "    # Save JSON log\n",
    "    json_path = os.path.join(MODEL_SAVE_DIR, f\"gridsearch_results_{datetime.now().strftime(\"%Y%m%d\")}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results_log, f, indent=4)\n",
    "\n",
    "    # Save CSV results\n",
    "    csv_path = os.path.join(MODEL_SAVE_DIR, f\"gridsearch_results_{datetime.now().strftime(\"%Y%m%d\")}.csv\")\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"params\", \"avg_f1\", \"std_f1\", \"mean_acc\", \"std_acc\", \"f1_scores\", \"acc_scores\", \"memory_used_GB\", \"time_taken\"]\n",
    "        writer.writerow(header)\n",
    "        for res in results_log[\"all_results\"]:\n",
    "            writer.writerow([\n",
    "                str(res[\"params\"]), res[\"avg_f1\"], res[\"std_f1\"],\n",
    "                res[\"mean_acc\"], res[\"std_acc\"],\n",
    "                res[\"f1_scores\"], res[\"acc_scores\"],\n",
    "                res[\"memory_used_GB\"], res[\"time_taken\"]\n",
    "            ])\n",
    "\n",
    "def bestTrainModel(filepath, best_params):\n",
    "    model, target_layer = getModel(best_params['model_name'], nClasses=NUM_CLASSES, dropout_rate=best_params['dropout_rate'])\n",
    "    train_loader, val_loader, test_loader = getDataloaders(filepath, None, best_params['batch_size'], True)\n",
    "    history, _ = trainModel(model, train_loader, val_loader, best_params)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    cam_images = genGRADCAM(model, target_layer, test_loader, species)\n",
    "    saveGRADCAM(cam_images, os.path.join(MODEL_SAVE_DIR, RESULT_DIR))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    top1_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_loss /= total_samples\n",
    "\n",
    "    labels_range = list(range(NUM_CLASSES))\n",
    "    try:\n",
    "        top3_acc = top_k_accuracy_score(all_labels, all_probs, k=3, labels=labels_range)\n",
    "    except ValueError:\n",
    "        top3_acc = 0.0  # fallback\n",
    "\n",
    "    try:\n",
    "        binarized_labels = label_binarize(all_labels, classes=labels_range)\n",
    "        auprc_macro = roc_auc_score(binarized_labels, all_probs, average='macro', multi_class='ovr')\n",
    "    except Exception:\n",
    "        auprc_macro = 0.0\n",
    "\n",
    "    # Compute PR curve for the first class (just for plotting)\n",
    "    precision, recall, _ = precision_recall_curve(binarized_labels[:, 0], all_probs[:, 0])\n",
    "\n",
    "    metrics = {\n",
    "        'test_loss': test_loss,\n",
    "        'top1_accuracy': top1_acc,\n",
    "        'top3_accuracy': top3_acc,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'macro_auprc': auprc_macro,\n",
    "        'precision': precision.tolist(),\n",
    "        'recall': recall.tolist(),\n",
    "    }\n",
    "\n",
    "    return model, history, metrics, cam_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c35181d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning GridSearch with 16 combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7598\n",
      "Fold 2 Best F1 Score: 0.7811\n",
      "Fold 3 Best F1 Score: 0.7774\n",
      "Fold 4 Best F1 Score: 0.7723\n",
      "Fold 5 Best F1 Score: 0.7939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [31:01<7:45:27, 1861.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best parameters found with F1: 0.7769\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7669\n",
      "Fold 2 Best F1 Score: 0.7748\n",
      "Fold 3 Best F1 Score: 0.7740\n",
      "Fold 4 Best F1 Score: 0.7853\n",
      "Fold 5 Best F1 Score: 0.7804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [1:00:40<7:02:59, 1812.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7569\n",
      "Fold 2 Best F1 Score: 0.7664\n",
      "Fold 3 Best F1 Score: 0.7613\n",
      "Fold 4 Best F1 Score: 0.7896\n",
      "Fold 5 Best F1 Score: 0.7797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [1:26:21<6:05:53, 1688.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7732\n",
      "Fold 2 Best F1 Score: 0.7713\n",
      "Fold 3 Best F1 Score: 0.7741\n",
      "Fold 4 Best F1 Score: 0.7840\n",
      "Fold 5 Best F1 Score: 0.7733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [1:55:20<5:41:44, 1708.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7598\n",
      "Fold 2 Best F1 Score: 0.7789\n",
      "Fold 3 Best F1 Score: 0.7700\n",
      "Fold 4 Best F1 Score: 0.7943\n",
      "Fold 5 Best F1 Score: 0.7649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [2:23:44<5:12:56, 1707.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7644\n",
      "Fold 2 Best F1 Score: 0.7671\n",
      "Fold 3 Best F1 Score: 0.7774\n",
      "Fold 4 Best F1 Score: 0.7932\n",
      "Fold 5 Best F1 Score: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [2:53:02<4:47:22, 1724.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best parameters found with F1: 0.7783\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7594\n",
      "Fold 2 Best F1 Score: 0.7572\n",
      "Fold 3 Best F1 Score: 0.7584\n",
      "Fold 4 Best F1 Score: 0.7725\n",
      "Fold 5 Best F1 Score: 0.7820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [3:17:48<4:06:57, 1646.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7694\n",
      "Fold 2 Best F1 Score: 0.7711\n",
      "Fold 3 Best F1 Score: 0.7723\n",
      "Fold 4 Best F1 Score: 0.7819\n",
      "Fold 5 Best F1 Score: 0.7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [3:43:45<3:35:44, 1618.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7606\n",
      "Fold 2 Best F1 Score: 0.7869\n",
      "Fold 3 Best F1 Score: 0.7839\n",
      "Fold 4 Best F1 Score: 0.7859\n",
      "Fold 5 Best F1 Score: 0.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [5:30:16<6:02:51, 3110.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best parameters found with F1: 0.7812\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7655\n",
      "Fold 2 Best F1 Score: 0.7688\n",
      "Fold 3 Best F1 Score: 0.7652\n",
      "Fold 4 Best F1 Score: 0.7569\n",
      "Fold 5 Best F1 Score: 0.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [8:22:43<8:54:25, 5344.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7798\n",
      "Fold 2 Best F1 Score: 0.7836\n",
      "Fold 3 Best F1 Score: 0.7424\n",
      "Fold 4 Best F1 Score: 0.7797\n",
      "Fold 5 Best F1 Score: 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [10:59:45<9:09:20, 6592.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7839\n",
      "Fold 2 Best F1 Score: 0.7779\n",
      "Fold 3 Best F1 Score: 0.7548\n",
      "Fold 4 Best F1 Score: 0.7804\n",
      "Fold 5 Best F1 Score: 0.7800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [12:38:20<7:05:44, 6386.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.8064\n",
      "Fold 2 Best F1 Score: 0.8288\n",
      "Fold 3 Best F1 Score: 0.7975\n",
      "Fold 4 Best F1 Score: 0.8142\n",
      "Fold 5 Best F1 Score: 0.8385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [13:49:01<4:46:49, 5736.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best parameters found with F1: 0.8171\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.8031\n",
      "Fold 2 Best F1 Score: 0.8119\n",
      "Fold 3 Best F1 Score: 0.7799\n",
      "Fold 4 Best F1 Score: 0.8038\n",
      "Fold 5 Best F1 Score: 0.8151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [14:50:16<2:50:27, 5113.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.8186\n",
      "Fold 2 Best F1 Score: 0.8048\n",
      "Fold 3 Best F1 Score: 0.8067\n",
      "Fold 4 Best F1 Score: 0.8181\n",
      "Fold 5 Best F1 Score: 0.8297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [15:56:59<1:19:38, 4778.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 32, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7930\n",
      "Fold 2 Best F1 Score: 0.8098\n",
      "Fold 3 Best F1 Score: 0.7939\n",
      "Fold 4 Best F1 Score: 0.8083\n",
      "Fold 5 Best F1 Score: 0.8311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [17:15:12<00:00, 3882.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GridSearch completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "# 1. Perform hyperparameter search\n",
    "params = {\n",
    "    'model_name': ['efficientnet_b0', 'efficientnet_V2'],\n",
    "    'learning_rate': [0.0005, 0.0001],\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'weight_decay': [0.0001, 0],\n",
    "    'optimizer': ['adamw'],\n",
    "    'scheduler': [True],\n",
    "    'dropout_rate': [0, 0.2]\n",
    "}\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_SAVE_DIR, RESULT_DIR), exist_ok=True)\n",
    "\n",
    "gridSearch(f\"{DATA_DIR}/{DATASET}\", N_SPLITS, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b543c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PARAMS = 'gridsearch_setup1_20250524.pth'\n",
    "best_params = torch.load(os.path.join(MODEL_SAVE_DIR, BEST_PARAMS))\n",
    "best_model, best_history, best_metrics, best_camImages = bestTrainModel(f\"{DATA_DIR}/{DATASET}\", best_params)\n",
    "speciesModel = best_model.species if hasattr(best_model, 'species') else species\n",
    "\n",
    "#Generate confusion matrix\n",
    "cm = best_metrics['confusion_matrix']\n",
    "        \n",
    "#Plot results\n",
    "plotting(\n",
    "    history=best_history,\n",
    "    cm=cm,\n",
    "    metrics_dict=best_metrics,\n",
    "    species=speciesModel,\n",
    "    cam_images=best_camImages\n",
    ")\n",
    "        \n",
    "# Save final model and metrics\n",
    "final_model_path = os.path.join(MODEL_SAVE_DIR, f'final_model_{datetime.now().strftime(\"%Y%m%d\")}.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': best_model.state_dict(),\n",
    "    'best_params': best_params,\n",
    "    'metrics': best_metrics,\n",
    "    'class_names': speciesModel,\n",
    "    'training_history': best_history\n",
    "}, final_model_path)\n",
    "\n",
    "# Save metrics separately\n",
    "with open(os.path.join(MODEL_SAVE_DIR, f\"final_metrics_{datetime.now().strftime(\"%Y%m%d\")}.json\"), 'w') as f:\n",
    "    json.dump({\n",
    "        'test_loss': best_metrics['test_loss'],\n",
    "        'top1_accuracy': best_metrics['top1_accuracy'],\n",
    "        'top3_accuracy': best_metrics['top3_accuracy'],\n",
    "        'f1_score': best_metrics['f1_score'],\n",
    "        'macro_auprc': best_metrics['macro_auprc'],\n",
    "        'precision_recall_curve': {\n",
    "            'precision': best_metrics['precision'],\n",
    "            'recall': best_metrics['recall']\n",
    "        },\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Save confusion matrix\n",
    "np.save(os.path.join(MODEL_SAVE_DIR, f\"confusion_matrix_{datetime.now().strftime(\"%Y%m%d\")}.npy\"), cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
