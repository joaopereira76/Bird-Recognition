{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be59eb13",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import models, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce1236",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "First, the list of chosen bird species is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195815a6",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "species = [\n",
    "    'Ciconia_ciconia', 'Columba_livia', 'Streptopelia_decaocto',\n",
    "    'Emberiza_calandra', 'Carduelis_carduelis', 'Serinus_serinus',\n",
    "    'Delichon_urbicum', 'Hirundo_rustica', 'Passer_domesticus',\n",
    "    'Sturnus_unicolor', 'Turdus_merula'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bb111",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "And some settings are defined for pre-processing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8d2f68",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'dataset'                        # Replace with your dataset path\n",
    "OUTPUT_FILE = 'bird_dataset_pytorch.h5'     # Output HDF5 file\n",
    "IMG_SIZE = (224, 224)                       # Standard size for CNNs\n",
    "TEST_SIZE = 0.1                             # Test set proportion\n",
    "COMPRESSION = 'gzip'                        # Compression type\n",
    "COMPRESSION_LEVEL = 7                       # Compression level (1-9)\n",
    "N_SPLITS = 5                                # Number of splits for cross-validation\n",
    "BATCH_SIZE = 32                             # Batch size for DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f0197",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "The images of the various birds must be transformed so that they can be used in the models, using PyTorch's transforms.Compose(). The transformations include data augmentation for the training set and basic preprocessing for the test set. But what is data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecc56e",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "Data Augmentation is a technique used to expand a training dataset by creating modified versions of existing images through random but realistic transformations. It helps improve model generalization by exposing it to varied examples without collecting new data. Common transformations include flipping, rotating, scaling, changing brightness/contrast, adding noise, or cropping. These variations simulate different real-world scenarios, making the model more robust to changes in viewpoint, lighting, or orientation.\n",
    "\n",
    "Data augmentation is applied only during training—validation and test data remain unmodified to reflect real-world performance. It is especially useful for small datasets, reducing overfitting and improving accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44959df",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "Let's now break down each component and explain the hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d631bbb",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "- transforms.Resize(IMG_SIZE)- Resizes the image to a fixed size. This size is typically chosen based on model architecture, in this case 224x224.\n",
    "\n",
    "- transforms.RandomHorizontalFlip()- Randomly flips the image horizontally with a default probability of 0.5.\n",
    "\n",
    "- transforms.RandomRotation(20)- Rotates the image randomly by up to ±20 degrees.\n",
    "\n",
    "- transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)- Randomly adjusts brightness, contrast, and saturation by up to ±10%.\n",
    "\n",
    "- transforms.ToTensor()- Converts the image to a PyTorch tensor (values scaled to [0, 1]).\n",
    "\n",
    "- transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])- Normalizes the image using precomputed mean and std from ImageNet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fc6886",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ae4eb",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111fb351",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    images = []\n",
    "    labels = []\n",
    "        \n",
    "    for idx, specie in enumerate(species):\n",
    "        specie_dir = os.path.join(DATA_DIR, specie)\n",
    "            \n",
    "        for img_name in os.listdir(specie_dir):\n",
    "            img_path = os.path.join(specie_dir, img_name)\n",
    "                \n",
    "            try:\n",
    "                img = Image.open(img_path)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                img = img.resize(IMG_SIZE)\n",
    "                images.append(np.array(img))  # Keep as uint8 [0,255]\n",
    "                labels.append(idx)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "    # Load and preprocess images\n",
    "    print(\"Loading and preprocessing images...\")\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=TEST_SIZE, stratify=y\n",
    "    )\n",
    "\n",
    "    #Cross Validation with Stratified K-Folds\n",
    "    cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "    #Saving in HDF5 format\n",
    "    print(f\"Saving data to {OUTPUT_FILE}...\")\n",
    "    with h5py.File(OUTPUT_FILE, 'w') as hf:\n",
    "        #Test set\n",
    "        test_group = hf.create_group('test')\n",
    "        test_group.create_dataset('X_test', data=X_test, compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "        test_group.create_dataset('y_test', data=y_test, compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "\n",
    "        # Cross-validation splits\n",
    "        cv_group = hf.create_group('cross_validation')\n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
    "            fold_group = cv_group.create_group(f'fold_{fold + 1}')\n",
    "            fold_group.create_dataset('X_train', data=X_train[train_idx], compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "            fold_group.create_dataset('y_train', data=y_train[train_idx], compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "            fold_group.create_dataset('X_val', data=X_train[val_idx], compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "            fold_group.create_dataset('y_val', data=y_train[val_idx], compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "\n",
    "        # Save metadata\n",
    "        hf.attrs['species'] = np.array(species, dtype=h5py.string_dtype())\n",
    "        hf.attrs['image_size'] = IMG_SIZE\n",
    "        hf.attrs['n_splits'] = N_SPLITS\n",
    "        hf.attrs['compression'] = COMPRESSION\n",
    "        hf.attrs['compression_level'] = COMPRESSION_LEVEL\n",
    "    print(\"Process completed successfully!\")\n",
    "    print(f\"Data saved to {OUTPUT_FILE} with {COMPRESSION} compression level {COMPRESSION_LEVEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20219c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataloaders(filepath, idx, batch_size=BATCH_SIZE):\n",
    "    with h5py.File(filepath, 'r') as hf:\n",
    "        X_test = hf['test/X_test'][:]\n",
    "        y_test = hf['test/y_test'][:]\n",
    "\n",
    "        fold_group = hf[f'cross_validation/fold_{idx}']\n",
    "        X_train = fold_group['X_train'][:]\n",
    "        y_train = fold_group['y_train'][:]\n",
    "        X_val = fold_group['X_val'][:]\n",
    "        y_val = fold_group['y_val'][:]\n",
    "\n",
    "        species = hf.attrs['species']\n",
    "    \n",
    "    # Apply transformations\n",
    "    X_train = np.array([train_transforms(Image.fromarray(img)) for img in X_train])\n",
    "    X_val = np.array([test_transforms(Image.fromarray(img)) for img in X_val])\n",
    "    X_test = np.array([test_transforms(Image.fromarray(img)) for img in X_test])\n",
    "\n",
    "\n",
    "    #Permute necessary for PyTorch (C, H, W) \n",
    "    X_train_tensor = torch.from_numpy(X_train).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train).long()\n",
    "    X_val_tensor = torch.from_numpy(X_val).float()\n",
    "    y_val_tensor = torch.from_numpy(y_val).long()\n",
    "    X_test_tensor = torch.from_numpy(X_test).float()\n",
    "    y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb16232b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreateDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m, in \u001b[0;36mcreateDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     14\u001b[0m     img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m images\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(img))  \u001b[38;5;66;03m# Keep as uint8 [0,255]\u001b[39;00m\n\u001b[1;32m     17\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(idx)\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/PIL/Image.py:2356\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2345\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2346\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2347\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2348\u001b[0m         )\n\u001b[1;32m   2349\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2350\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2351\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2352\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2353\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2354\u001b[0m         )\n\u001b[0;32m-> 2356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "createDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae37ea3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_SAVE_DIR = 'saved_models'\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Hyperparameter search space\n",
    "HYPERPARAMS = {\n",
    "    'model_name': ['resnet18', 'efficientnet_b0', 'resnet34'],\n",
    "    'learning_rate': [0.001, 0.0005, 0.0001],\n",
    "    'batch_size': [32, 64],\n",
    "    'weight_decay': [0, 1e-4, 1e-3],\n",
    "    'optimizer': ['adam', 'sgd'],\n",
    "    'scheduler': [True, False],\n",
    "    'dropout_rate': [0, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Cross-validation\n",
    "NUM_EPOCHS = 30\n",
    "NUM_CLASSES = 11\n",
    "\n",
    "def getModel(name, nClasses, dropout_rate=0):\n",
    "    if name == 'resnet18':\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.fc.in_features, nClasses)\n",
    "        )\n",
    "    elif name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "    elif name == 'resnet34':\n",
    "        model = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.fc.in_features, nClasses)\n",
    "        )\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def getOptimizer(model, params):\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=params['weight_decay'])\n",
    "    return optimizer\n",
    "\n",
    "def trainModel(model, train_loader, val_loader, params):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getOptimizer(model, params)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3) if params['scheduler'] else None\n",
    "    \n",
    "    best_f1 = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            inputs = inputs.permute(0, 3, 1, 2)  # NHWC to NCHW\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                inputs = inputs.permute(0, 3, 1, 2)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, f'best_{params[\"model_name\"]}_fold.pth'))\n",
    "            print(f'Novo melhor modelo salvo com F1: {best_f1:.4f}')\n",
    "\n",
    "    return history, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aca8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "def gridSearch(filepath, n_splits=N_SPLITS):\n",
    "    best_params = None\n",
    "    best_f1 = 0\n",
    "    \n",
    "    # Generate all possible hyperparameter combinations\n",
    "    keys, values = zip(*HYPERPARAMS.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    \n",
    "    print(f\"Starting hyperparameter search with {len(param_combinations)} combinations...\")\n",
    "    \n",
    "    for params in tqdm(param_combinations):\n",
    "        print(f\"\\nTesting combination: {params}\")\n",
    "        fold_f1_scores = []\n",
    "        \n",
    "        # Cross-validation loop\n",
    "        for fold_idx in range(1, n_splits+1):\n",
    "            train_loader, val_loader, _, species = getDataloaders(filepath, fold_idx, params['batch_size'])\n",
    "            print(f\"Validating {species} on fold {fold_idx}\")\n",
    "            model = getModel(params['model_name'], NUM_CLASSES)\n",
    "            _, fold_f1 = trainModel(model, train_loader, val_loader, params)\n",
    "            fold_f1_scores.append(fold_f1)\n",
    "            \n",
    "            # Clear memory\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Calculate average F1 across folds\n",
    "        avg_f1 = np.mean(fold_f1_scores)\n",
    "        print(f\"Average F1 across folds: {avg_f1:.4f}\")\n",
    "        \n",
    "        # Update best parameters if improved\n",
    "        if avg_f1 > best_f1:\n",
    "            best_f1 = avg_f1\n",
    "            best_params = params\n",
    "            print(f\"New best parameters found with F1: {best_f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nHyperparameter search completed!\")\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "    print(f\"Best average F1 score: {best_f1:.4f}\")\n",
    "    \n",
    "    return best_params\n",
    "\n",
    "def bestTrainModel(filepath, best_params):\n",
    "    train_loader, val_loader, test_loader, species = getDataloaders(filepath, 1, best_params['batch_size'])\n",
    "    trainset = torch.utils.data.ConcatDataset([train_loader.dataset, val_loader.dataset])\n",
    "    trainloaderset = DataLoader(trainset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    model = getModel(best_params['model_name'], NUM_CLASSES, best_params['dropout_rate'])\n",
    "    bestHist,_ = trainModel(model, trainloaderset, test_loader, best_params)\n",
    "\n",
    "    #Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    test_loss = 0.0\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    print(\"\\nFinal Model Evaluation:\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    return model, bestHist, (all_labels, all_preds), test_loss, test_acc, test_f1\n",
    "\n",
    "    \n",
    "\n",
    "def plotting(history, cm, test_metrics, species):\n",
    "    \"\"\"Visualize training results and metrics\"\"\"\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(history['train_acc'], label='Train Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(history['val_f1'], label='Validation F1')\n",
    "    plt.title('Validation F1 Score')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.subplot(2, 2, 4)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=species, yticklabels=species)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print test metrics\n",
    "    print(\"\\nTest Set Metrics:\")\n",
    "    print(f\"Loss: {test_metrics[0]:.4f}\")\n",
    "    print(f\"Accuracy: {test_metrics[1]:.4f}\")\n",
    "    print(f\"F1 Score: {test_metrics[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "# 1. Perform hyperparameter search\n",
    "best_params = gridSearch(OUTPUT_FILE, N_SPLITS)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1baa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Train final model with best parameters\n",
    "final_model, history, (true_labels, pred_labels), test_loss, test_acc, test_f1 = bestTrainModel(OUTPUT_FILE, best_params)\n",
    "    \n",
    "# 3. Generate confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "    \n",
    "# 4. Plot results\n",
    "plotting(history, cm, (test_loss, test_acc, test_f1), final_model.species if hasattr(final_model, 'species') else species)\n",
    "    \n",
    "# 5. Save final model\n",
    "torch.save({\n",
    "    'model_state_dict': final_model.state_dict(),\n",
    "    'best_params': best_params,\n",
    "    'test_metrics': (test_loss, test_acc, test_f1)\n",
    "}, os.path.join(MODEL_SAVE_DIR, 'final_model.pth'))\n",
    "print(\"\\nFinal model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
