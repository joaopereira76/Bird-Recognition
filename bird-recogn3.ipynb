{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be59eb13",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, top_k_accuracy_score, precision_recall_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torchcam.methods import GradCAM\n",
    "from torchvision import transforms\n",
    "from torchcam.utils import overlay_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce1236",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "First, the list of chosen bird species is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195815a6",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "species = [\n",
    "    'Ciconia_ciconia', 'Columba_livia', 'Streptopelia_decaocto',\n",
    "    'Emberiza_calandra', 'Carduelis_carduelis', 'Serinus_serinus',\n",
    "    'Delichon_urbicum', 'Hirundo_rustica', 'Passer_domesticus',\n",
    "    'Sturnus_unicolor', 'Turdus_merula'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bb111",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "And some settings are defined for pre-processing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8d2f68",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_DIR = 'saved_models/phase1'\n",
    "RESULT_DIR = 'images'  \n",
    "DATA_DIR = \"new_dataset\"\n",
    "DATASET = 'dataset_20250506_145756.h5'\n",
    "BATCH_SIZE = [16]\n",
    "N_SPLITS = 3                            \n",
    "NUM_EPOCHS = 5\n",
    "NUM_CLASSES = 11\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20219c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openH5File(filepath, fold_idx=None):\n",
    "    file = h5py.File(filepath, 'r')\n",
    "    datasets = {}\n",
    "\n",
    "    if fold_idx is not None:\n",
    "        try:\n",
    "            fold_group = file[f'cross_validation/fold_{fold_idx}']\n",
    "            datasets['X_train'] = fold_group['X_train']\n",
    "            datasets['y_train'] = fold_group['y_train']\n",
    "            datasets['X_val'] = fold_group['X_val']\n",
    "            datasets['y_val'] = fold_group['y_val']\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Fold {fold_idx} not found in file. Available groups: {list(file['cross_validation'].keys())}\")\n",
    "    \n",
    "    datasets['X_test'] = file['test']['X_test']\n",
    "    datasets['y_test'] = file['test']['y_test']\n",
    "    return datasets\n",
    "\n",
    "\n",
    "\n",
    "def createDataloaders(X_h5, y_h5, batch_size=BATCH_SIZE, shuffle=False):\n",
    "    X_np = X_h5[:]  # (N, H, W, C)\n",
    "    if X_np.ndim == 4:\n",
    "        X_np = np.transpose(X_np, (0, 3, 1, 2))  # to (N, C, H, W)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X_np).float()\n",
    "    y_tensor = torch.from_numpy(y_h5[:]).long()\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "def getDataloaders(filepath, fold_idx, batch_size):\n",
    "    dataset = openH5File(filepath, fold_idx)\n",
    "    test_loader = createDataloaders(dataset['X_test'], dataset['y_test'], batch_size=batch_size, shuffle=False)\n",
    "    if fold_idx is not None:\n",
    "        train_loader = createDataloaders(dataset['X_train'], dataset['y_train'], batch_size=batch_size, shuffle=True)\n",
    "        val_loader = createDataloaders(dataset['X_val'], dataset['y_val'], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae37ea3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getModel(name, nClasses, dropout_rate=0):\n",
    "    if name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "    elif name == 'efficientnet_V2':\n",
    "        model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def getOptimizer(model, params):\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'adamw':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    return optimizer\n",
    "\n",
    "def trainModel(model, train_loader, val_loader, params):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getOptimizer(model, params)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3) if params['scheduler'] else None\n",
    "    \n",
    "    best_f1 = 0\n",
    "    THRESHOLD = 5\n",
    "    improvementCounter = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            improvementCounter = 0\n",
    "        else:\n",
    "            improvementCounter +=1\n",
    "            if improvementCounter >= THRESHOLD:\n",
    "                break\n",
    "\n",
    "    return history, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74aca8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(filepath, n_splits, hyperparams):\n",
    "    results_log = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_combinations\": len(list(itertools.product(*hyperparams.values()))),\n",
    "        \"best_f1\": 0,\n",
    "        \"best_params\": None,\n",
    "        \"all_results\": []\n",
    "    }\n",
    "\n",
    "    # Generate all possible hyperparameter combinations\n",
    "    keys, values = zip(*hyperparams.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    print(f\"\\nBeginning GridSearch with {len(param_combinations)} combinations...\")\n",
    "    \n",
    "    for params in tqdm(param_combinations):\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Testing combination: {params}\")\n",
    "        fold_f1_scores = []\n",
    "        fold_acc_scores = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Cross-validation loop\n",
    "        for fold_idx in range(1, n_splits+1):\n",
    "            train_loader, val_loader, _ = getDataloaders(filepath, fold_idx, params['batch_size'])\n",
    "            model = getModel(params['model_name'], NUM_CLASSES, params.get('dropout_rate', 0))\n",
    "            model.to(DEVICE)\n",
    "            history, fold_f1 = trainModel(model, train_loader, val_loader, params)\n",
    "            print(f\"Fold {fold_idx} Best F1 Score: {fold_f1:.4f}\")\n",
    "            fold_f1_scores.append(fold_f1)\n",
    "            fold_acc_scores.append(history['val_acc'][-1].item())\n",
    "\n",
    "            # Clear memory\n",
    "            del model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Calculate average F1 across folds\n",
    "        avg_f1 = np.mean(fold_f1_scores)\n",
    "        std_f1 = np.std(fold_f1_scores)\n",
    "        avg_acc = np.mean(fold_acc_scores)\n",
    "        std_acc = np.std(fold_acc_scores)\n",
    "        time_taken = time.time() - start_time\n",
    "\n",
    "        # Record this combination's results\n",
    "        result_entry = {\n",
    "            \"params\": params,\n",
    "            \"avg_f1\": avg_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_acc\": avg_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"f1_scores\": fold_f1_scores,\n",
    "            \"acc_scores\": fold_acc_scores,\n",
    "            \"memory_used_GB\": torch.cuda.max_memory_allocated()/1e9,\n",
    "            \"time_taken\": time_taken\n",
    "        }\n",
    "        results_log[\"all_results\"].append(result_entry)\n",
    "        \n",
    "        # Update best parameters if improved\n",
    "        if avg_f1 > results_log[\"best_f1\"]:\n",
    "            results_log[\"best_f1\"] = avg_f1\n",
    "            results_log[\"best_params\"] = params\n",
    "            print(f\"New best parameters found with F1: {results_log[\"best_f1\"]:.4f}\")\n",
    "\n",
    "    #Finalize results        \n",
    "    print(\"\\nGridSearch completed!\")\n",
    "    torch.save(results_log[\"best_params\"], os.path.join(MODEL_SAVE_DIR, f'gridsearch_setup1_{datetime.now().isoformat()}.pth'))\n",
    "\n",
    "    # Save JSON log\n",
    "    json_path = os.path.join(MODEL_SAVE_DIR, f\"gridsearch_results_{datetime.now().isoformat()}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results_log, f, indent=4)\n",
    "\n",
    "    # Save CSV results\n",
    "    csv_path = os.path.join(MODEL_SAVE_DIR, f\"gridsearch_results_{datetime.now().isoformat()}.csv\")\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"params\", \"avg_f1\", \"std_f1\", \"mean_acc\", \"std_acc\", \"f1_scores\", \"acc_scores\", \"memory_used_GB\", \"time_taken\"]\n",
    "        writer.writerow(header)\n",
    "        for res in results_log[\"all_results\"]:\n",
    "            writer.writerow([\n",
    "                str(res[\"params\"]), res[\"avg_f1\"], res[\"std_f1\"],\n",
    "                res[\"mean_acc\"], res[\"std_acc\"],\n",
    "                res[\"f1_scores\"], res[\"acc_scores\"],\n",
    "                res[\"memory_used_GB\"], res[\"time_taken\"]\n",
    "            ])\n",
    "\n",
    "def bestTrainModel(filepath, best_params):\n",
    "    model = getModel(best_params['model_name'], nClasses=NUM_CLASSES, dropout_rate=best_params['dropout_rate'])\n",
    "    train_loader, val_loader, test_loader = getDataloaders(filepath, fold_idx=1, batch_size=BATCH_SIZE[0])\n",
    "\n",
    "    history, _ = trainModel(model, train_loader, val_loader, best_params)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    cam_images = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_probs = np.array(all_probs)\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    top1_acc = accuracy_score(all_labels, all_preds)\n",
    "    test_loss /= total_samples\n",
    "\n",
    "    labels_range = list(range(NUM_CLASSES))\n",
    "    try:\n",
    "        top3_acc = top_k_accuracy_score(all_labels, all_probs, k=3, labels=labels_range)\n",
    "    except ValueError:\n",
    "        top3_acc = 0.0  # fallback\n",
    "\n",
    "    try:\n",
    "        binarized_labels = label_binarize(all_labels, classes=labels_range)\n",
    "        auprc_macro = roc_auc_score(binarized_labels, all_probs, average='macro', multi_class='ovr')\n",
    "    except Exception:\n",
    "        auprc_macro = 0.0  # fallback\n",
    "\n",
    "    # Compute PR curve for the first class (just for plotting)\n",
    "    precision, recall, _ = precision_recall_curve(binarized_labels[:, 0], all_probs[:, 0])\n",
    "\n",
    "    metrics = {\n",
    "        'test_loss': test_loss,\n",
    "        'top1_accuracy': top1_acc,\n",
    "        'top3_accuracy': top3_acc,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'macro_auprc': auprc_macro,\n",
    "        'precision': precision.tolist(),\n",
    "        'recall': recall.tolist()\n",
    "    }\n",
    "\n",
    "    return model, history, metrics, cam_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57fbcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting(history, cm, metrics_dict, species, cam_images=None):\n",
    "    plt.figure(figsize=(24, 12))\n",
    "\n",
    "    # Plot training history\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.subplot(2, 3, 2)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=species, yticklabels=species)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Plot precision-recall curve\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(metrics_dict['recall'],\n",
    "            metrics_dict['precision'], lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve (AUPRC: {metrics_dict[\"macro_auprc\"]:.4f})')\n",
    "\n",
    "    # Plot Grad-CAM visualizations\n",
    "    for i, (img, activation, label) in enumerate(cam_images[:3]):\n",
    "        plt.subplot(2, 3, 4+i)\n",
    "        result = overlay_mask(\n",
    "            to_pil_image(img), \n",
    "            to_pil_image(activation[0].squeeze(0), mode='F'), \n",
    "            alpha=0.5\n",
    "        )\n",
    "        plt.imshow(result)\n",
    "        plt.title(f'True: {species[label]}\\nPred: {species[torch.argmax(activation)]}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(MODEL_SAVE_DIR, RESULT_DIR, f\"training_results_{datetime.now().isoformat()}.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save individual Grad-CAM images\n",
    "    for i, (img, activation, label) in enumerate(cam_images[:3]):\n",
    "        result = overlay_mask(\n",
    "            to_pil_image(img), \n",
    "            to_pil_image(activation[0].squeeze(0), mode='F'), \n",
    "            alpha=0.5\n",
    "        )\n",
    "        result.save(os.path.join(MODEL_SAVE_DIR, RESULT_DIR, f\"gradcam_{i}_{datetime.now().isoformat()}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b61ebf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Beginning GridSearch with 16 combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7496\n",
      "Fold 2 Best F1 Score: 0.7270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 1/16 [11:58<2:59:38, 718.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7552\n",
      "New best parameters found with F1: 0.7439\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7526\n",
      "Fold 2 Best F1 Score: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2/16 [23:59<2:47:59, 719.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7306\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7465\n",
      "Fold 2 Best F1 Score: 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 3/16 [35:59<2:35:59, 719.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7243\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7345\n",
      "Fold 2 Best F1 Score: 0.7462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 4/16 [47:59<2:23:59, 719.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7443\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7770\n",
      "Fold 2 Best F1 Score: 0.7936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 5/16 [1:00:01<2:12:08, 720.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7826\n",
      "New best parameters found with F1: 0.7844\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7934\n",
      "Fold 2 Best F1 Score: 0.7725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 6/16 [1:12:03<2:00:12, 721.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7736\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7777\n",
      "Fold 2 Best F1 Score: 0.7901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 7/16 [1:24:04<1:48:09, 721.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7798\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_b0', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7948\n",
      "Fold 2 Best F1 Score: 0.7846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 8/16 [1:36:05<1:36:08, 721.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7813\n",
      "New best parameters found with F1: 0.7869\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /home/w4ter/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82.7M/82.7M [00:29<00:00, 2.95MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Best F1 Score: 0.7203\n",
      "Fold 2 Best F1 Score: 0.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 9/16 [2:02:12<1:54:57, 985.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7238\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7160\n",
      "Fold 2 Best F1 Score: 0.7296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 10/16 [2:27:48<1:55:33, 1155.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7191\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.7233\n",
      "Fold 2 Best F1 Score: 0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 11/16 [2:53:19<1:45:51, 1270.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7198\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0005, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.7322\n",
      "Fold 2 Best F1 Score: 0.7260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 12/16 [3:18:51<1:30:00, 1350.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.7343\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.8340\n",
      "Fold 2 Best F1 Score: 0.8195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 13/16 [3:44:29<1:10:20, 1406.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.8175\n",
      "New best parameters found with F1: 0.8237\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0.0001, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.8356\n",
      "Fold 2 Best F1 Score: 0.8288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 14/16 [4:10:09<48:14, 1447.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.8284\n",
      "New best parameters found with F1: 0.8309\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0}\n",
      "Fold 1 Best F1 Score: 0.8275\n",
      "Fold 2 Best F1 Score: 0.8191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 15/16 [4:35:42<24:33, 1473.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best F1 Score: 0.8245\n",
      "\n",
      "==================================================\n",
      "Testing combination: {'model_name': 'efficientnet_V2', 'learning_rate': 0.0001, 'batch_size': 16, 'weight_decay': 0, 'optimizer': 'adamw', 'scheduler': True, 'dropout_rate': 0.2}\n",
      "Fold 1 Best F1 Score: 0.8382\n",
      "Fold 2 Best F1 Score: 0.8279\n",
      "Fold 3 Best F1 Score: 0.8218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [5:01:16<00:00, 1129.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GridSearch completed!\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "# 1. Perform hyperparameter search\n",
    "params = {\n",
    "    'model_name': ['efficientnet_b0', 'efficientnet_V2'],\n",
    "    'learning_rate': [0.0005, 0.0001],\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'weight_decay': [0.0001, 0],\n",
    "    'optimizer': ['adamw'],\n",
    "    'scheduler': [True],\n",
    "    'dropout_rate': [0, 0.2]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_SAVE_DIR, RESULT_DIR), exist_ok=True)\n",
    "\n",
    "gridSearch(f\"{DATA_DIR}/{DATASET}\", N_SPLITS, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1baa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_PARAMS = 'gridsearch_setup1_2025-05-06T20:48:47.915540.pth'\n",
    "\n",
    "# 2. Train final model with best parameters\n",
    "best_params = torch.load(os.path.join(MODEL_SAVE_DIR, BEST_PARAMS))\n",
    "best_model, best_history, best_metrics, best_camImages  = bestTrainModel(f\"{DATA_DIR}/{DATASET}\", best_params)\n",
    "speciesModel = best_model.species if hasattr(best_model, 'species') else species\n",
    "\n",
    "# 3. Generate confusion matrix\n",
    "cm = best_metrics['confusion_matrix']\n",
    "    \n",
    "# 4. Plot results\n",
    "plotting(\n",
    "    history=best_history,\n",
    "    cm=cm,\n",
    "    metrics_dict=best_metrics,\n",
    "    species=speciesModel,\n",
    "    cam_images=best_camImages\n",
    ")\n",
    "    \n",
    "# 5. Save final model and metrics\n",
    "final_model_path = os.path.join(MODEL_SAVE_DIR, f'final_model_{datetime.now().isoformat()}.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': best_model.state_dict(),\n",
    "    'best_params': best_params,\n",
    "    'metrics': best_metrics,\n",
    "    'class_names': speciesModel,\n",
    "    'training_history': best_history\n",
    "}, final_model_path)\n",
    "\n",
    "# Save metrics separately\n",
    "with open(os.path.join(MODEL_SAVE_DIR, f\"final_metrics_{datetime.now().isoformat()}.json\"), 'w') as f:\n",
    "    json.dump({\n",
    "        'test_loss': best_metrics['test_loss'],\n",
    "        'top1_accuracy': best_metrics['top1_accuracy'],\n",
    "        'top3_accuracy': best_metrics['top3_accuracy'],\n",
    "        'f1_score': best_metrics['f1_score'],\n",
    "        'macro_auprc': best_metrics['macro_auprc'],\n",
    "        'precision_recall_curve': {\n",
    "            'precision': best_metrics['precision'],\n",
    "            'recall': best_metrics['recall']\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Save confusion matrix\n",
    "np.save(os.path.join(MODEL_SAVE_DIR, f\"confusion_matrix_{datetime.now().isoformat()}.npy\"), cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
