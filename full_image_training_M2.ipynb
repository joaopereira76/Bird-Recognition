{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be59eb13",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, top_k_accuracy_score, precision_recall_curve, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from torchcam.methods import GradCAM\n",
    "from torchvision import transforms\n",
    "from torchcam.utils import overlay_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce1236",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "First, the list of chosen bird species is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "195815a6",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "species = [\n",
    "    'Ciconia_ciconia', 'Columba_livia', 'Streptopelia_decaocto',\n",
    "    'Emberiza_calandra', 'Carduelis_carduelis', 'Serinus_serinus',\n",
    "    'Delichon_urbicum', 'Hirundo_rustica', 'Passer_domesticus',\n",
    "    'Sturnus_unicolor', 'Turdus_merula'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bb111",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "And some settings are defined for pre-processing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8d2f68",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "MODEL_SAVE_DIR = 'saved_models/full_image_model'\n",
    "RESULT_DIR = 'images'  \n",
    "DATA_DIR = \"full_image_dataset\"\n",
    "AUGMENTED_DATA_DIR = \"augmented_dataset\"\n",
    "DATASET = 'dataset_20250519.h5'\n",
    "BATCH_SIZE = [16]\n",
    "N_SPLITS = 5                            \n",
    "NUM_EPOCHS = 25\n",
    "NUM_CLASSES = len(species)\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Experiment B parameters\n",
    "MIXUP_ALPHA = 0.2\n",
    "CUTMIX_ALPHA = 1.0\n",
    "USE_MIXUP = True\n",
    "USE_CUTMIX = True\n",
    "\n",
    "# Experiment E parameters\n",
    "UNCERTAINTY_THRESHOLD = 0.6\n",
    "\n",
    "#GRADCAM\n",
    "ACTIVATION = None\n",
    "GRADIENT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20219c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openH5File(filepath, fold_idx=None):\n",
    "    file = h5py.File(filepath, 'r')\n",
    "    datasets = {}\n",
    "\n",
    "    if fold_idx is not None:\n",
    "        try:\n",
    "            fold_group = file[f'cross_validation/fold_{fold_idx}']\n",
    "            datasets['X_train'] = fold_group['X_train']\n",
    "            datasets['y_train'] = fold_group['y_train']\n",
    "            datasets['X_val'] = fold_group['X_val']\n",
    "            datasets['y_val'] = fold_group['y_val']\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Fold {fold_idx} not found in file. Available groups: {list(file['cross_validation'].keys())}\")\n",
    "    \n",
    "    datasets['X_test'] = file['test']['X_test']\n",
    "    datasets['y_test'] = file['test']['y_test']\n",
    "    return datasets\n",
    "\n",
    "def createDataloaders(X_h5, y_h5, batch_size=BATCH_SIZE, shuffle=False):\n",
    "    X_np = X_h5[:]  # (N, H, W, C)\n",
    "    if X_np.ndim == 4:\n",
    "        X_np = np.transpose(X_np, (0, 3, 1, 2))  # to (N, C, H, W)\n",
    "\n",
    "    X_tensor = torch.from_numpy(X_np).float()\n",
    "    y_tensor = torch.from_numpy(y_h5[:]).long()\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    dataloader = DataLoader(dataset, batch_size, shuffle, num_workers=4, pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "def getDataloaders(filepath, fold_idx, batch_size):\n",
    "    dataset = openH5File(f\"{filepath}\", fold_idx)\n",
    "    test_loader = createDataloaders(dataset['X_test'], dataset['y_test'], batch_size)\n",
    "    if fold_idx is not None:\n",
    "        train_loader = createDataloaders(dataset['X_train'], dataset['y_train'], batch_size, shuffle=True)\n",
    "        val_loader = createDataloaders(dataset['X_val'], dataset['y_val'], batch_size)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eae37ea3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def getModel(name, nClasses, dropout_rate=0):\n",
    "    if name == 'efficientnet_b0':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "    elif name == 'efficientnet_V2':\n",
    "        model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(model.classifier[1].in_features, nClasses)\n",
    "        )\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "\n",
    "def getOptimizer(model, params):\n",
    "    if params['optimizer'] == 'adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'sgd':\n",
    "        optimizer = optim.SGD(model.parameters(), lr=params['learning_rate'], momentum=0.9, weight_decay=params['weight_decay'])\n",
    "    elif params['optimizer'] == 'adamw':\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def apply_mixup_cutmix(inputs, labels, params):\n",
    "    \"\"\"Applies MixUp or CutMix augmentation to a batch\"\"\"\n",
    "    if not (USE_MIXUP or USE_CUTMIX):\n",
    "        return inputs, (labels, labels, 1.0)\n",
    "    \n",
    "    use_mixup = params.get('use_mixup', False)\n",
    "    use_cutmix = params.get('use_cutmix', False)\n",
    "    \n",
    "    if use_cutmix:\n",
    "        lam = np.random.beta(CUTMIX_ALPHA, CUTMIX_ALPHA)\n",
    "        b, _, h, w = inputs.size()\n",
    "        \n",
    "        # Generate random bounding box\n",
    "        rx = random.randint(0, w)\n",
    "        ry = random.randint(0, h)\n",
    "        rw = int(w * np.sqrt(1 - lam))\n",
    "        rh = int(h * np.sqrt(1 - lam))\n",
    "        x1 = max(0, rx - rw // 2)\n",
    "        y1 = max(0, ry - rh // 2)\n",
    "        x2 = min(w, x1 + rw)\n",
    "        y2 = min(h, y1 + rh)\n",
    "        \n",
    "        # Apply CutMix\n",
    "        inputs[:, :, y1:y2, x1:x2] = inputs.flip(0)[:, :, y1:y2, x1:x2]\n",
    "        lam = 1 - (x2 - x1) * (y2 - y1) / (w * h)\n",
    "    else:\n",
    "        # Apply MixUp\n",
    "        lam = np.random.beta(MIXUP_ALPHA, MIXUP_ALPHA)\n",
    "        inputs = lam * inputs + (1 - lam) * inputs.flip(0)\n",
    "    \n",
    "    # Return mixed labels and lambda\n",
    "    return inputs, (labels, labels.flip(0), lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1127e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, train_loader, val_loader, params):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = getOptimizer(model, params)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3) if params['scheduler'] else None\n",
    "    \n",
    "    best_f1 = 0\n",
    "    THRESHOLD = 5\n",
    "    improvementCounter = 0\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [], 'val_f1': []}\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            \n",
    "            # Apply MixUp/CutMix only during training\n",
    "            if USE_MIXUP or USE_CUTMIX:\n",
    "                inputs, (labels1, labels2, lam) = apply_mixup_cutmix(inputs, labels, params)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if USE_MIXUP or USE_CUTMIX:\n",
    "                loss = lam * criterion(outputs, labels1) + (1 - lam) * criterion(outputs, labels2)\n",
    "            else:\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
    "        history['train_loss'].append(epoch_loss)\n",
    "        history['train_acc'].append(epoch_acc)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        val_acc = val_running_corrects.double() / len(val_loader.dataset)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        \n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_f1'].append(val_f1)\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step(val_loss)\n",
    "        \n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            improvementCounter = 0\n",
    "        else:\n",
    "            improvementCounter += 1\n",
    "            if improvementCounter >= THRESHOLD:\n",
    "                break\n",
    "\n",
    "    return history, best_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fbcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_gradcams(model, test_loader, species_list):\n",
    "    \"\"\"Generate one Grad-CAM visualization per class\"\"\"\n",
    "    original_training = model.training\n",
    "    model.eval()\n",
    "    \n",
    "    target_layer = get_last_conv_layer(model)\n",
    "    cam_extractor = GradCAM(model, target_layer=target_layer)\n",
    "    class_samples = {i: None for i in range(len(species_list))}\n",
    "    \n",
    "    # First pass: find one correct prediction per class\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "        for i in range(inputs.size(0)):\n",
    "            label = labels[i].item()\n",
    "            if class_samples[label] is None and preds[i] == label:\n",
    "                class_samples[label] = inputs[i].unsqueeze(0)\n",
    "        if all(v is not None for v in class_samples.values()):\n",
    "            break\n",
    "    \n",
    "    # Second pass: generate Grad-CAM\n",
    "    cam_results = []\n",
    "    for class_idx, img_tensor in class_samples.items():\n",
    "        if img_tensor is None:\n",
    "            continue\n",
    "        \n",
    "        img = img_tensor.clone().detach().requires_grad_(True)\n",
    "        with torch.set_grad_enabled(True):\n",
    "            out = model(img)\n",
    "            activation_map = cam_extractor(out.squeeze(0).argmax().item(), out)\n",
    "\n",
    "            if activation_map is not None:\n",
    "                img_vis = img_tensor.squeeze().cpu()\n",
    "                result = overlay_mask(\n",
    "                    to_pil_image(img_vis),\n",
    "                    to_pil_image(activation_map[0].squeeze(0)), \n",
    "                    alpha=0.5\n",
    "                )\n",
    "                cam_results.append({\n",
    "                    'class_name': species_list[class_idx],\n",
    "                    'image': np.array(result),\n",
    "                    'true_label': species_list[class_idx],\n",
    "                    'pred_label': species_list[class_idx]\n",
    "                })\n",
    "    \n",
    "    cam_extractor.remove_hooks()\n",
    "    model.train(original_training)\n",
    "    \n",
    "    return cam_results\n",
    "\n",
    "\n",
    "def get_last_conv_layer(model):\n",
    "    \"\"\"Dynamically find the last Conv2d layer in EfficientNet.\"\"\"\n",
    "    conv_layers = []\n",
    "\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d):\n",
    "            conv_layers.append(module)\n",
    "\n",
    "    if not conv_layers:\n",
    "        raise ValueError(\"No Conv2d layers found in model.\")\n",
    "\n",
    "    return conv_layers[-1]\n",
    "\n",
    "\n",
    "def save_class_gradcams(gradcam_results, save_dir):\n",
    "    \"\"\"Save Grad-CAM visualizations per class\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for result in gradcam_results:\n",
    "        filename = f\"gradcam_{result['class_name']}.png\"\n",
    "        result['image'].save(os.path.join(save_dir, filename))\n",
    "        \n",
    "def plot_class_gradcams(gradcam_results):\n",
    "    \"\"\"Plot Grad-CAM visualizations in a grid\"\"\"\n",
    "    n_classes = len(gradcam_results)\n",
    "    cols = 3\n",
    "    rows = (n_classes + cols - 1) // cols\n",
    "    \n",
    "    plt.figure(figsize=(15, 5*rows))\n",
    "    for i, result in enumerate(gradcam_results):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(result['image'])\n",
    "        plt.title(result['class_name'])\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def plotting(history, cm, metrics_dict, species, cam_images=None):\n",
    "    plt.figure(figsize=(24, 12))\n",
    "\n",
    "    # Plot training history\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.plot(history['train_loss'], label='Train Loss')\n",
    "    plt.plot(history['val_loss'], label='Val Loss')\n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.subplot(2, 3, 2)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=species, yticklabels=species)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "\n",
    "    # Plot precision-recall curve\n",
    "    plt.subplot(2, 3, 3)\n",
    "    plt.plot(metrics_dict['recall'],\n",
    "            metrics_dict['precision'], lw=2)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve (AUPRC: {metrics_dict[\"macro_auprc\"]:.4f})')\n",
    "\n",
    "    # Plot Grad-CAM visualizations\n",
    "    if cam_images:\n",
    "        for i, result in enumerate(cam_images[:6]):  # Show max 6\n",
    "            plt.subplot(2, 3, 4+i)  # Adjust grid position as needed\n",
    "            plt.imshow(result['image'])\n",
    "            plt.title(result['class_name'])\n",
    "            plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(MODEL_SAVE_DIR, RESULT_DIR, f\"training_results_{datetime.now().strftime(\"%Y%m%d\")}.png\")\n",
    "    plt.savefig(plot_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Save individual Grad-CAM images\n",
    "    if cam_images:\n",
    "        for i, cam_entry in enumerate(cam_images[:3]):\n",
    "            img_path = os.path.join(MODEL_SAVE_DIR, RESULT_DIR, f\"gradcam_{i}_{datetime.now().strftime('%Y%m%d')}.png\")\n",
    "            Image.fromarray(cam_entry['image']).save(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74aca8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch(filepath, n_splits, hyperparams):\n",
    "    results_log = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "        \"total_combinations\": len(list(itertools.product(*hyperparams.values()))),\n",
    "        \"best_f1\": 0,\n",
    "        \"best_params\": None,\n",
    "        \"all_results\": []\n",
    "    }\n",
    "\n",
    "    # Generate all possible hyperparameter combinations\n",
    "    keys, values = zip(*hyperparams.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "    print(f\"\\nBeginning GridSearch with {len(param_combinations)} combinations...\")\n",
    "    \n",
    "    for params in tqdm(param_combinations):\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"Testing combination: {params}\")\n",
    "        fold_f1_scores = []\n",
    "        fold_acc_scores = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Cross-validation loop\n",
    "        for fold_idx in range(1, n_splits+1):\n",
    "            train_loader, val_loader, _ = getDataloaders(filepath, fold_idx, params['batch_size'])\n",
    "            model = getModel(params['model_name'], NUM_CLASSES, params.get('dropout_rate', 0))\n",
    "            model.to(DEVICE)\n",
    "            history, fold_f1 = trainModel(model, train_loader, val_loader, params)\n",
    "            print(f\"Fold {fold_idx} Best F1 Score: {fold_f1:.4f}\")\n",
    "            fold_f1_scores.append(fold_f1)\n",
    "            fold_acc_scores.append(history['val_acc'][-1].item())\n",
    "\n",
    "            # Clear memory\n",
    "            del model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        # Calculate average F1 across folds\n",
    "        avg_f1 = np.mean(fold_f1_scores)\n",
    "        std_f1 = np.std(fold_f1_scores)\n",
    "        avg_acc = np.mean(fold_acc_scores)\n",
    "        std_acc = np.std(fold_acc_scores)\n",
    "        time_taken = time.time() - start_time\n",
    "\n",
    "        # Record this combination's results\n",
    "        result_entry = {\n",
    "            \"params\": params,\n",
    "            \"avg_f1\": avg_f1,\n",
    "            \"std_f1\": std_f1,\n",
    "            \"mean_acc\": avg_acc,\n",
    "            \"std_acc\": std_acc,\n",
    "            \"f1_scores\": fold_f1_scores,\n",
    "            \"acc_scores\": fold_acc_scores,\n",
    "            \"memory_used_GB\": torch.cuda.max_memory_allocated()/1e9,\n",
    "            \"time_taken\": time_taken\n",
    "        }\n",
    "        results_log[\"all_results\"].append(result_entry)\n",
    "        \n",
    "        # Update best parameters if improved\n",
    "        if avg_f1 > results_log[\"best_f1\"]:\n",
    "            results_log[\"best_f1\"] = avg_f1\n",
    "            results_log[\"best_params\"] = params\n",
    "            print(f\"New best parameters found with F1: {avg_f1:.4f}\")\n",
    "\n",
    "    # Finalize results        \n",
    "    print(\"\\nGridSearch completed!\")\n",
    "    torch.save(results_log[\"best_params\"], os.path.join(MODEL_SAVE_DIR, f'gridsearch_setup1_{datetime.now().strftime(\"%Y%m%d\")}.pth'))\n",
    "\n",
    "    # Save JSON log\n",
    "    json_path = os.path.join(MODEL_SAVE_DIR, f\"gridsearch_results_{datetime.now().strftime(\"%Y%m%d\")}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(results_log, f, indent=4)\n",
    "\n",
    "    # Save CSV results\n",
    "    csv_path = os.path.join(MODEL_SAVE_DIR, f\"gridsearch_results_{datetime.now().strftime(\"%Y%m%d\")}.csv\")\n",
    "    with open(csv_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        header = [\"params\", \"avg_f1\", \"std_f1\", \"mean_acc\", \"std_acc\", \"f1_scores\", \"acc_scores\", \"memory_used_GB\", \"time_taken\"]\n",
    "        writer.writerow(header)\n",
    "        for res in results_log[\"all_results\"]:\n",
    "            writer.writerow([\n",
    "                str(res[\"params\"]), res[\"avg_f1\"], res[\"std_f1\"],\n",
    "                res[\"mean_acc\"], res[\"std_acc\"],\n",
    "                res[\"f1_scores\"], res[\"acc_scores\"],\n",
    "                res[\"memory_used_GB\"], res[\"time_taken\"]\n",
    "            ])\n",
    "\n",
    "def bestTrainModel(filepath, best_params):\n",
    "    model = getModel(best_params['model_name'], nClasses=NUM_CLASSES, dropout_rate=best_params['dropout_rate'])\n",
    "    train_loader, val_loader, test_loader = getDataloaders(filepath, fold_idx=1, batch_size=BATCH_SIZE[0])\n",
    "\n",
    "    history, _ = trainModel(model, train_loader, val_loader, best_params)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    all_probs = []\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    test_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    cam_images = generate_class_gradcams(model, test_loader, species)\n",
    "    # Save and plot\n",
    "    save_class_gradcams(cam_images, os.path.join(MODEL_SAVE_DIR, RESULT_DIR))\n",
    "    plot_class_gradcams(cam_images)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            max_probs, preds = torch.max(probs, dim=1)\n",
    "            \n",
    "            # Apply uncertainty threshold (Experiment E)\n",
    "            uncertain_mask = max_probs < UNCERTAINTY_THRESHOLD\n",
    "            preds[uncertain_mask] = -1  # Mark as uncertain\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Filter out uncertain predictions for metrics calculation\n",
    "    certain_mask = np.array(all_preds) != -1\n",
    "    certain_preds = np.array(all_preds)[certain_mask]\n",
    "    certain_labels = np.array(all_labels)[certain_mask]\n",
    "    certain_probs = np.array(all_probs)[certain_mask]\n",
    "\n",
    "    cm = confusion_matrix(certain_labels, certain_preds)\n",
    "    f1 = f1_score(certain_labels, certain_preds, average='weighted')\n",
    "    top1_acc = accuracy_score(certain_labels, certain_preds)\n",
    "    test_loss /= total_samples\n",
    "\n",
    "    labels_range = list(range(NUM_CLASSES))\n",
    "    try:\n",
    "        top3_acc = top_k_accuracy_score(certain_labels, certain_probs, k=3, labels=labels_range)\n",
    "    except ValueError:\n",
    "        top3_acc = 0.0\n",
    "\n",
    "    try:\n",
    "        binarized_labels = label_binarize(certain_labels, classes=labels_range)\n",
    "        auprc_macro = roc_auc_score(binarized_labels, certain_probs, average='macro', multi_class='ovr')\n",
    "    except Exception:\n",
    "        auprc_macro = 0.0\n",
    "\n",
    "    # Compute PR curve for the first class (just for plotting)\n",
    "    precision, recall, _ = precision_recall_curve(binarized_labels[:, 0], certain_probs[:, 0])\n",
    "\n",
    "    metrics = {\n",
    "        'test_loss': test_loss,\n",
    "        'top1_accuracy': top1_acc,\n",
    "        'top3_accuracy': top3_acc,\n",
    "        'f1_score': f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'macro_auprc': auprc_macro,\n",
    "        'precision': precision.tolist(),\n",
    "        'recall': recall.tolist(),\n",
    "        'uncertainty_rate': 1 - (certain_mask.sum() / len(all_preds)),\n",
    "        'threshold': UNCERTAINTY_THRESHOLD\n",
    "    }\n",
    "\n",
    "    return model, history, metrics, cam_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc1baa01",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot register a hook on a tensor that doesn't require gradient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m BEST_PARAMS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridsearch_setup1_20250506.pth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m best_params \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_SAVE_DIR, BEST_PARAMS))\n\u001b[0;32m----> 5\u001b[0m best_model, best_history, best_metrics, best_camImages \u001b[38;5;241m=\u001b[39m \u001b[43mbestTrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATA_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mDATASET\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m speciesModel \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mspecies \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(best_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspecies\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m species\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Generate confusion matrix\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 102\u001b[0m, in \u001b[0;36mbestTrainModel\u001b[0;34m(filepath, best_params)\u001b[0m\n\u001b[1;32m     99\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    100\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 102\u001b[0m cam_images \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_class_gradcams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Save and plot\u001b[39;00m\n\u001b[1;32m    104\u001b[0m save_class_gradcams(cam_images, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MODEL_SAVE_DIR, RESULT_DIR))\n",
      "Cell \u001b[0;32mIn[7], line 14\u001b[0m, in \u001b[0;36mgenerate_class_gradcams\u001b[0;34m(model, test_loader, species_list)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     13\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(DEVICE), labels\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 14\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/container.py:240\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 240\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1857\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/nn/modules/module.py:1818\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1816\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1818\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1821\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torchcam/methods/gradient.py:49\u001b[0m, in \u001b[0;36m_GradCAM._hook_g\u001b[0;34m(self, module, input, output, idx)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Gradient hook\"\"\"\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks_enabled:\n\u001b[0;32m---> 49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_handles\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_store_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/AP/lib/python3.13/site-packages/torch/_tensor.py:688\u001b[0m, in \u001b[0;36mTensor.register_hook\u001b[0;34m(self, hook)\u001b[0m\n\u001b[1;32m    686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39mregister_hook, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, hook)\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot register a hook on a tensor that doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt require gradient\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot register a hook on a tensor that doesn't require gradient"
     ]
    }
   ],
   "source": [
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(os.path.join(MODEL_SAVE_DIR, RESULT_DIR), exist_ok=True)\n",
    "BEST_PARAMS = 'gridsearch_setup1_20250506.pth'\n",
    "best_params = torch.load(os.path.join(MODEL_SAVE_DIR, BEST_PARAMS))\n",
    "best_model, best_history, best_metrics, best_camImages = bestTrainModel(f\"{DATA_DIR}/{DATASET}\", best_params)\n",
    "speciesModel = best_model.species if hasattr(best_model, 'species') else species\n",
    "\n",
    "#Generate confusion matrix\n",
    "cm = best_metrics['confusion_matrix']\n",
    "        \n",
    "#Plot results\n",
    "plotting(\n",
    "    history=best_history,\n",
    "    cm=cm,\n",
    "    metrics_dict=best_metrics,\n",
    "    species=speciesModel,\n",
    "    cam_images=best_camImages\n",
    ")\n",
    "        \n",
    "# Save final model and metrics\n",
    "final_model_path = os.path.join(MODEL_SAVE_DIR, f'final_model_{datetime.now().strftime(\"%Y%m%d\")}.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': best_model.state_dict(),\n",
    "    'best_params': best_params,\n",
    "    'metrics': best_metrics,\n",
    "    'class_names': speciesModel,\n",
    "    'training_history': best_history\n",
    "}, final_model_path)\n",
    "\n",
    "# Save metrics separately\n",
    "with open(os.path.join(MODEL_SAVE_DIR, f\"final_metrics_{datetime.now().strftime(\"%Y%m%d\")}.json\"), 'w') as f:\n",
    "    json.dump({\n",
    "        'test_loss': best_metrics['test_loss'],\n",
    "        'top1_accuracy': best_metrics['top1_accuracy'],\n",
    "        'top3_accuracy': best_metrics['top3_accuracy'],\n",
    "        'f1_score': best_metrics['f1_score'],\n",
    "        'macro_auprc': best_metrics['macro_auprc'],\n",
    "        'precision_recall_curve': {\n",
    "            'precision': best_metrics['precision'],\n",
    "            'recall': best_metrics['recall']\n",
    "        },\n",
    "        'uncertainty_rate': best_metrics['uncertainty_rate'],\n",
    "        'threshold': best_metrics['threshold']\n",
    "    }, f, indent=2)\n",
    "\n",
    "# Save confusion matrix\n",
    "np.save(os.path.join(MODEL_SAVE_DIR, f\"confusion_matrix_{datetime.now().strftime(\"%Y%m%d\")}.npy\"), cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
