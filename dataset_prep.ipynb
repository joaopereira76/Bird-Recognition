{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e34d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90861/1428048763.py:12: DeprecationWarning: The module `pyinaturalist.node_api` is deprecated; please use `from pyinaturalist import ...`\n",
      "  from pyinaturalist.node_api import get_observations\n"
     ]
    }
   ],
   "source": [
    "import pygbif\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import imagehash\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "from pyinaturalist.node_api import get_observations\n",
    "from ebird.api import get_observations as ebird_get_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9265288",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"new_dataset\"          # Expected input dir: species_name/*.jpg\n",
    "CLEAN_DATA_DIR = \"clean_dataset\"      # Output cleaned dir\n",
    "IMG_SIZE_THRESHOLD = 200              # Min resolution (px)\n",
    "HASH_THRESHOLD = 8                    # Duplicate threshold using phash\n",
    "EBIRD_API_KEY = \"r2qmi9gi3gpg\"\n",
    "\n",
    "species_keys = {\n",
    "    \"Carduelis carduelis\": 2494686,\n",
    "    \"Ciconia ciconia\": 2481912,\n",
    "    \"Columba livia\": 2495414,\n",
    "    \"Delichon urbicum\": 2489214,\n",
    "    \"Emberiza calandra\":7634625,\n",
    "    \"Hirundo rustica\": 7192162,\n",
    "    \"Passer domesticus\": 5231190,\n",
    "    \"Serinus serinus\":2494200,\n",
    "    \"Streptopelia decaocto\": 2495696,\n",
    "    \"Sturnus unicolor\":2489104,\n",
    "    \"Turdus merula\": 6171845   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd2301b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isValidImage(path):\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        if min(img.size) < IMG_SIZE_THRESHOLD:\n",
    "            return False\n",
    "        img.verify()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def getPhash(path):\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        return imagehash.phash(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating hash for {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def downloadImages_INaturalist(species_name, output_dir, limit=500):\n",
    "    results = get_observations(\n",
    "        taxon_name=species_name,\n",
    "        per_page=limit,\n",
    "        quality_grade=\"research\",\n",
    "        media_type=\"photo\",\n",
    "        license=[\"CC-BY\",\"CC-BY-NC\"] \n",
    "    )\n",
    "\n",
    "    images_downloaded = 0\n",
    "    seen_urls = set()\n",
    "\n",
    "    for obs in tqdm(results[\"results\"]):\n",
    "        if \"photos\" not in obs:\n",
    "            continue\n",
    "        for photo in obs[\"photos\"]:\n",
    "            url = photo.get(\"url\", \"\")\n",
    "            if not url or url in seen_urls:\n",
    "                continue\n",
    "            seen_urls.add(url)\n",
    "            try:\n",
    "                # Full-size image (not thumbnail)\n",
    "                full_url = url.replace(\"square\", \"original\")\n",
    "                response = requests.get(full_url, timeout=10)\n",
    "                if response.status_code == 200:\n",
    "                    image_ext = full_url.split(\".\")[-1].split(\"?\")[0]\n",
    "                    filename = f\"{species_name.replace(' ', '_')}_{images_downloaded}.{image_ext}\"\n",
    "                    file_path = os.path.join(output_dir, filename)\n",
    "                    with open(file_path, \"wb\") as f:\n",
    "                        f.write(response.content)\n",
    "                    images_downloaded += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "            if images_downloaded >= limit:\n",
    "                break\n",
    "        if images_downloaded >= limit:\n",
    "            break\n",
    "\n",
    "    print(f\"Downloaded {images_downloaded} images for {species_name}\")\n",
    "    return images_downloaded\n",
    "\n",
    "def downloadImages_GBIF(species_name, downloadedValue, output_dir, limit=500):\n",
    "    taxon_key = species_keys[species_name]\n",
    "    images_downloaded = downloadedValue+1\n",
    "    \n",
    "    try:\n",
    "        # Fetch occurrences from GBIF\n",
    "        occurrences = pygbif.occurrences.search(\n",
    "            taxonKey=taxon_key,\n",
    "            mediaType=\"StillImage\",\n",
    "            limit=limit\n",
    "        )\n",
    "        \n",
    "        for idx, occ in enumerate(occurrences[\"results\"]):\n",
    "            if images_downloaded >= limit:\n",
    "                break\n",
    "                \n",
    "            if \"media\" not in occ:\n",
    "                continue\n",
    "                \n",
    "            # Process each media item that is a still image\n",
    "            for media in occ[\"media\"]:\n",
    "                if media.get(\"type\") != \"StillImage\":\n",
    "                    continue\n",
    "                    \n",
    "                imgURL = media.get(\"identifier\")\n",
    "                if not imgURL:\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    # Download the image\n",
    "                    response = requests.get(imgURL, timeout=10)\n",
    "                    response.raise_for_status()\n",
    "                    \n",
    "                    # Determine file extension from content type\n",
    "                    content_type = response.headers.get('content-type', 'image/jpeg')\n",
    "                    ext = 'jpg' if 'jpeg' in content_type else 'png'\n",
    "                    \n",
    "                    # Save the image\n",
    "                    filename = f\"{species_name.replace(' ', '_')}_{images_downloaded}.{ext}\"\n",
    "                    filepath = os.path.join(output_dir, filename)\n",
    "                    \n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(response.content)\n",
    "                        \n",
    "                    images_downloaded += 1\n",
    "                    print(f\"Downloaded image {images_downloaded}/{limit}\", end='\\r')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"\\nError downloading image {idx} for {species_name}: {e}\")\n",
    "                    continue\n",
    "                    \n",
    "    except Exception as e:\n",
    "        print(f\"\\nError fetching occurrences for {species_name}: {e}\")\n",
    "    \n",
    "    print(f\"Downloaded {images_downloaded - downloadedValue} GBIF images for {species_name}\")\n",
    "    return images_downloaded\n",
    "\n",
    "\n",
    "def downloadImages_eBird(species_name , downloadedValue , output_dir, limit=500):\n",
    "    ## Get the species code from the species name\n",
    "    headers = {'X-eBirdApiToken': EBIRD_API_KEY}\n",
    "    region = 'world'\n",
    "    # Step 1: Get species code (with 403 error handling)\n",
    "    try:\n",
    "        # Try direct taxonomy lookup first\n",
    "        taxon_url = \"https://api.ebird.org/v2/ref/taxon/find\"\n",
    "        response = requests.get(taxon_url, headers=headers, params={'species': species_name})\n",
    "        response.raise_for_status()\n",
    "        specie_code = response.json()[0]['speciesCode']\n",
    "    except requests.HTTPError as e:\n",
    "        if e.response.status_code == 403:\n",
    "            # Fallback: Search recent observations for the species code\n",
    "            print(\"Taxonomy endpoint blocked, using observation search fallback...\")\n",
    "            obs_search_url = f\"https://api.ebird.org/v2/data/obs/{region}/recent\"\n",
    "            response = requests.get(obs_search_url, headers=headers, params={'species': species_name})\n",
    "            response.raise_for_status()\n",
    "            if not response.json():\n",
    "                raise ValueError(f\"No observations found for {species_name}\")\n",
    "            specie_code = response.json()[0]['speciesCode']\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    # Step 2: Download images\n",
    "    images_downloaded = 0\n",
    "    obs_url = f\"https://api.ebird.org/v2/data/obs/{region}/recent?speciesCode={specie_code}\"\n",
    "    observations = requests.get(obs_url, headers=headers).json()\n",
    "    \n",
    "    with tqdm(total=limit, desc=f\"Downloading {species_name}\") as pbar:\n",
    "        for obs in observations:\n",
    "            if images_downloaded >= limit:\n",
    "                break\n",
    "                \n",
    "            if obs.get('hasMedia'):\n",
    "                try:\n",
    "                    # Get media details\n",
    "                    media_url = f\"https://api.ebird.org/v2/observation/{obs['subId']}\"\n",
    "                    media_data = requests.get(media_url, headers=headers).json()\n",
    "                    \n",
    "                    for media in media_data.get('media', []):\n",
    "                        if media['type'] == 'photo':\n",
    "                            try:\n",
    "                                img_url = media['url']\n",
    "                                response = requests.get(img_url, stream=True, timeout=15)\n",
    "                                ext = 'jpg' if 'jpeg' in response.headers.get('content-type','') else 'png'\n",
    "                                filename = f\"{specie_code}_{images_downloaded}.{ext}\"\n",
    "                                \n",
    "                                with open(os.path.join(output_dir, filename), 'wb') as f:\n",
    "                                    for chunk in response.iter_content(8192):\n",
    "                                        f.write(chunk)\n",
    "                                \n",
    "                                images_downloaded += 1\n",
    "                                pbar.update(1)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Image download failed: {e}\")\n",
    "                                continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Observation processing failed: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    print(f\"\\nDownloaded {images_downloaded} images for {species_name} ({specie_code})\")\n",
    "    return images_downloaded\n",
    "\n",
    "\n",
    "\n",
    "def downloadImages(species_name, output_dir, limit=500):\n",
    "    output_dir = os.path.join(RAW_DATA_DIR, species_name.replace(\" \", \"_\"))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\nDownloading images for: {species_name}\")\n",
    "    downloadedValue = downloadImages_INaturalist(species_name, output_dir, limit)\n",
    "    downloadedValue = downloadImages_GBIF(species_name, downloadedValue, output_dir, limit)\n",
    "    #downloadedValue = downloadImages_eBird(species_name, downloadedValue, output_dir, limit)\n",
    "    print(f\"Total images downloaded for {species_name}: {downloadedValue}\")\n",
    "\n",
    "def cleanData(species_name):\n",
    "    hash_db = defaultdict(list)\n",
    "    total_removed = 0\n",
    "    print(\"Starting image extraction and cleaning...\")\n",
    "\n",
    "    for species in os.listdir(RAW_DATA_DIR):\n",
    "        if species_name and species not in species_name:\n",
    "            continue\n",
    "        species_path = os.path.join(RAW_DATA_DIR, species)\n",
    "        \n",
    "        if not os.path.isdir(species_path):\n",
    "            continue\n",
    "\n",
    "        imgsRemove = []\n",
    "        for img_path in species_path.glob(\"*.*\"):\n",
    "            if not isValidImage(img_path):\n",
    "                imgsRemove.append(img_path)\n",
    "                continue\n",
    "\n",
    "            phash = getPhash(img_path)\n",
    "            if phash is None:\n",
    "                imgsRemove.append(img_path)\n",
    "                continue\n",
    "\n",
    "            # Check for duplicates\n",
    "            is_duplicate = any(phash - existing < HASH_THRESHOLD \n",
    "                             for existing in hash_db[species])\n",
    "            if is_duplicate:\n",
    "                imgsRemove.append(img_path)\n",
    "            else:\n",
    "                hash_db[species].append(phash)\n",
    "\n",
    "        # Remove invalid/duplicate files\n",
    "        for img_path in imgsRemove:\n",
    "            os.remove(img_path)\n",
    "            total_removed += 1\n",
    "\n",
    "\n",
    "    print(f\"Finished cleaning. Total Images Removed: {total_removed}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "007f3d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Carduelis+carduelis&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading images for: Carduelis carduelis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:36<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 266 images for Carduelis carduelis\n",
      "Downloaded image 693/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Ciconia+ciconia&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 428 GBIF images for Carduelis carduelis\n",
      "Total images downloaded for Carduelis carduelis: 694\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Ciconia ciconia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [07:39<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 255 images for Ciconia ciconia\n",
      "Downloaded image 738/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Columba+livia&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 484 GBIF images for Ciconia ciconia\n",
      "Total images downloaded for Ciconia ciconia: 739\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Columba livia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [14:50<00:00,  4.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 300 images for Columba livia\n",
      "Downloaded image 774/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Delichon+urbicum&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 475 GBIF images for Columba livia\n",
      "Total images downloaded for Columba livia: 775\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Delichon urbicum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [11:19<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 398 images for Delichon urbicum\n",
      "Downloaded image 889/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Emberiza+calandra&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 492 GBIF images for Delichon urbicum\n",
      "Total images downloaded for Delichon urbicum: 890\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Emberiza calandra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [08:28<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 294 images for Emberiza calandra\n",
      "Downloaded image 818/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Hirundo+rustica&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 525 GBIF images for Emberiza calandra\n",
      "Total images downloaded for Emberiza calandra: 819\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Hirundo rustica\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:32<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 343 images for Hirundo rustica\n",
      "Downloaded image 874/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Passer+domesticus&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 532 GBIF images for Hirundo rustica\n",
      "Total images downloaded for Hirundo rustica: 875\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Passer domesticus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:40<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 290 images for Passer domesticus\n",
      "Downloaded image 836/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Serinus+serinus&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 547 GBIF images for Passer domesticus\n",
      "Total images downloaded for Passer domesticus: 837\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Serinus serinus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [09:25<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 279 images for Serinus serinus\n",
      "Downloaded image 787/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Streptopelia+decaocto&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 509 GBIF images for Serinus serinus\n",
      "Total images downloaded for Serinus serinus: 788\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Streptopelia decaocto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [11:01<00:00,  3.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 321 images for Streptopelia decaocto\n",
      "Downloaded image 767/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Sturnus+unicolor&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 447 GBIF images for Streptopelia decaocto\n",
      "Total images downloaded for Streptopelia decaocto: 768\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Sturnus unicolor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:10<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 261 images for Sturnus unicolor\n",
      "Downloaded image 634/2000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Request:\n",
      "GET https://api.inaturalist.org/v1/observations?license=CC-BY%2CCC-BY-NC&quality_grade=research&taxon_name=Turdus+merula&per_page=2000&media_type=photo\n",
      "User-Agent: python-requests/2.32.3 pyinaturalist/0.20.1\n",
      "Accept-Encoding: gzip, deflate, br\n",
      "Accept: application/json\n",
      "Connection: keep-alive\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 374 GBIF images for Sturnus unicolor\n",
      "Total images downloaded for Sturnus unicolor: 635\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n",
      "\n",
      "Downloading images for: Turdus merula\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [06:28<00:00,  1.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 267 images for Turdus merula\n",
      "Downloaded image 600/2000\n",
      "Error downloading image 162 for Turdus merula: HTTPSConnectionPool(host='inaturalist-open-data.s3.amazonaws.com', port=443): Read timed out.\n",
      "Downloaded 569 GBIF images for Turdus merula\n",
      "Total images downloaded for Turdus merula: 836\n",
      "Starting image extraction and cleaning...\n",
      "Finished cleaning. Total Images Removed: 0\n"
     ]
    }
   ],
   "source": [
    "for species in species_keys.keys():\n",
    "    downloadImages(species, RAW_DATA_DIR, limit=2000)\n",
    "    cleanData(species)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
