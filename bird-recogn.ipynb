{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "be59eb13",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce1236",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "First, the list of chosen bird species is defined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195815a6",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "species = [\n",
    "    'Ciconia_ciconia', 'Columba_livia', 'Streptopelia_decaocto',\n",
    "    'Emberiza_calandra', 'Carduelis_carduelis', 'Serinus_serinus',\n",
    "    'Delichon_urbicum', 'Hirundo_rustica', 'Passer_domesticus',\n",
    "    'Sturnus_unicolor', 'Turdus_merula'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7bb111",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "And some settings are defined for pre-processing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d2f68",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'dataset'  # Replace with your dataset path\n",
    "OUTPUT_FILE = 'bird_dataset_pytorch.h5'  # Output HDF5 file\n",
    "IMG_SIZE = (224, 224)             # Standard size for CNNs\n",
    "TEST_SIZE = 0.1                   # Test set proportion\n",
    "COMPRESSION = 'gzip'              # Compression type\n",
    "COMPRESSION_LEVEL = 7             # Compression level (1-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589f0197",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "The images of the various birds must be transformed so that they can be used in the models, using PyTorch's transforms.Compose(). The transformations include data augmentation for the training set and basic preprocessing for the test set. But what is data augmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecc56e",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "Data Augmentation is a technique used to expand a training dataset by creating modified versions of existing images through random but realistic transformations. It helps improve model generalization by exposing it to varied examples without collecting new data. Common transformations include flipping, rotating, scaling, changing brightness/contrast, adding noise, or cropping. These variations simulate different real-world scenarios, making the model more robust to changes in viewpoint, lighting, or orientation.\n",
    "\n",
    "Data augmentation is applied only during training—validation and test data remain unmodified to reflect real-world performance. It is especially useful for small datasets, reducing overfitting and improving accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44959df",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "Let's now break down each component and explain the hyperparameters:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d631bbb",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "- transforms.Resize(IMG_SIZE)- Resizes the image to a fixed size. This size is typically chosen based on model architecture, in this case 224x224.\n",
    "\n",
    "- transforms.RandomHorizontalFlip()- Randomly flips the image horizontally with a default probability of 0.5.\n",
    "\n",
    "- transforms.RandomRotation(20)- Rotates the image randomly by up to ±20 degrees.\n",
    "\n",
    "- transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1)- Randomly adjusts brightness, contrast, and saturation by up to ±10%.\n",
    "\n",
    "- transforms.ToTensor()- Converts the image to a PyTorch tensor (values scaled to [0, 1]).\n",
    "\n",
    "- transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])- Normalizes the image using precomputed mean and std from ImageNet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc6886",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ae4eb",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "111fb351",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data to bird_dataset_pytorch.h5...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process completed successfully!\n",
      "Data saved to bird_dataset_pytorch.h5 with gzip compression level 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images = []\n",
    "labels = []\n",
    "    \n",
    "for idx, specie in enumerate(species_list):\n",
    "    specie_dir = os.path.join(data_dir, specie)\n",
    "        \n",
    "    for img_name in os.listdir(specie_dir):\n",
    "        img_path = os.path.join(specie_dir, img_name)\n",
    "            \n",
    "        try:\n",
    "            img = Image.open(img_path)\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            img = img.resize(img_size)\n",
    "            images.append(np.array(img))  # Keep as uint8 [0,255]\n",
    "            labels.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "# Load and preprocess images\n",
    "print(\"Loading and preprocessing images...\")\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y\n",
    ")\n",
    "\n",
    "# Save data to HDF5 file\n",
    "print(f\"Saving data to {OUTPUT_FILE}...\")\n",
    "with h5py.File(OUTPUT_FILE, 'w') as hf:\n",
    "    # Save datasets with compression\n",
    "    hf.create_dataset('X_train', data=X_train, compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "    hf.create_dataset('y_train', data=y_train, compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "    hf.create_dataset('X_test', data=X_test, compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "    hf.create_dataset('y_test', data=y_test, compression=COMPRESSION, compression_opts=COMPRESSION_LEVEL)\n",
    "    \n",
    "    # Save metadata\n",
    "    hf.attrs['species'] = np.array(species, dtype=h5py.string_dtype())\n",
    "    hf.attrs['image_size'] = IMG_SIZE\n",
    "\n",
    "print(\"Process completed successfully!\")\n",
    "print(f\"Data saved to {OUTPUT_FILE} with {COMPRESSION} compression level {COMPRESSION_LEVEL}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a78994c",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 1. Load data from HDF5\n",
    "with h5py.File('bird_dataset_pytorch.h5', 'r') as hf:\n",
    "    X_train = hf['X_train'][:]\n",
    "    y_train = hf['y_train'][:]\n",
    "    X_test  = hf['X_test'][:]\n",
    "    y_test  = hf['y_test'][:]\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, stratify=y)\n",
    "\n",
    "\n",
    "y_train_tensor = torch.from_numpy(y_train).long()\n",
    "y_val_tensor = torch.from_numpy(y_val).long()\n",
    "y_test_tensor = torch.from_numpy(y_test).long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5181991c",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# After saving the data, you can load it like this:\n",
    "train_loader, test_loader, species = get_dataloaders('bird_dataset_pytorch.h5', batch_size=32)\n",
    "\n",
    "# Example training loop:\n",
    "for epoch in range(num_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Your training code here\n",
    "        pass\n",
    "    \n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            # Your evaluation code here\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae37ea3",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import models, transforms\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Configurações\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_CLASSES = 11  # 11 espécies de aves\n",
    "H5_PATH = 'bird_dataset_pytorch.h5'\n",
    "MODEL_SAVE_DIR = 'saved_models'\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# Função para carregar modelo pré-treinado\n",
    "def get_model(model_name, num_classes):\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    elif model_name == 'efficientnet':\n",
    "        model = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Modelo não suportado\")\n",
    "    \n",
    "    return model.to(DEVICE)\n",
    "\n",
    "# Função para treinar o modelo\n",
    "def train_model(model, criterion, optimizer, scheduler=None):\n",
    "    best_f1 = 0.0\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Fase de treino\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_dataset)\n",
    "        epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(epoch_acc)\n",
    "        \n",
    "        # Fase de validação\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_running_corrects = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(DEVICE)\n",
    "                labels = labels.to(DEVICE)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_epoch_loss = val_running_loss / len(test_dataset)\n",
    "        val_epoch_acc = val_running_corrects.double() / len(test_dataset)\n",
    "        val_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "        val_losses.append(val_epoch_loss)\n",
    "        val_accs.append(val_epoch_acc)\n",
    "        \n",
    "        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "        print(f'Val Loss: {val_epoch_loss:.4f} Acc: {val_epoch_acc:.4f} F1: {val_f1:.4f}')\n",
    "        \n",
    "        # Atualizar learning rate\n",
    "        if scheduler:\n",
    "            scheduler.step(val_epoch_loss)\n",
    "        \n",
    "        # Salvar melhor modelo\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, f'best_{model.__class__.__name__}.pth'))\n",
    "            print(f'Novo melhor modelo salvo com F1: {best_f1:.4f}')\n",
    "    \n",
    "    # Plotar métricas\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accs, label='Train Acc')\n",
    "    plt.plot(val_accs, label='Val Acc')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(os.path.join(MODEL_SAVE_DIR, 'training_metrics.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Treinar ResNet18\n",
    "print(\"\\nTreinando ResNet18...\")\n",
    "resnet = get_model('resnet18', NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "train_model(resnet, criterion, optimizer, scheduler)\n",
    "\n",
    "# Treinar EfficientNet\n",
    "print(\"\\nTreinando EfficientNet...\")\n",
    "efficientnet = get_model('efficientnet', NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(efficientnet.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True)\n",
    "\n",
    "train_model(efficientnet, criterion, optimizer, scheduler)\n",
    "\n",
    "print(\"Treino concluído! Modelos salvos em:\", MODEL_SAVE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
